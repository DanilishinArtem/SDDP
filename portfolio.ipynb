{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import pandas\n",
    "from discretize import generator, MarkovSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_88901/2864953890.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  beta = torch.tensor(coeffs['beta'])\n",
      "/tmp/ipykernel_88901/2864953890.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  alpha = torch.tensor(coeffs['alpha'])\n",
      "/tmp/ipykernel_88901/2864953890.py:16: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  beta = torch.tensor(coeffs['beta'])\n",
      "/tmp/ipykernel_88901/2864953890.py:17: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  sigma = torch.tensor(coeffs['epsilon'])\n"
     ]
    }
   ],
   "source": [
    "# number of stages:\n",
    "T = 25\n",
    "# number of assets:\n",
    "N = 3\n",
    "# risk free interest rate:\n",
    "rf = 0.0005\n",
    "# additional dataset:\n",
    "fee = 0.001\n",
    "# size of MC:\n",
    "size = 25\n",
    " \n",
    "coeffs = pandas.read_csv(\"./data/coefficients.csv\",index_col=0)\n",
    "beta = torch.tensor(coeffs['beta'])\n",
    "\n",
    "alpha = torch.tensor(coeffs['alpha'])\n",
    "beta = torch.tensor(coeffs['beta'])\n",
    "sigma = torch.tensor(coeffs['epsilon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(alpha,sigma):\n",
    "    def inner(random_state):\n",
    "        return random_state.normal(alpha+1,sigma)\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markov chain discterization\n",
    "markovian = MarkovSampler(generator, n_Markov_states=[1] + [100] * (T - 1), n_samples=size)\n",
    "markovian.SA()\n",
    "Markov_states = [None for _ in range(T)]\n",
    "transition_matrix = markovian.train_transition_matrix\n",
    "for t in range(T):\n",
    "    # Markov_states (time, states, ((r_Mt, epsilon_Mt, sigma^2_Mt)))\n",
    "    market_return = markovian.Markov_states[t][:,0].reshape(-1,1)\n",
    "    asset_return_market_exposure = beta[:N] * (market_return - rf) + rf\n",
    "    Markov_states[t] = torch.cat((asset_return_market_exposure, markovian.Markov_states[t]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented Markovian process generator\n",
    "def generator_augmented(random_state, size, T):\n",
    "    # (r_it, r_Mt, epsilon_Mt, sigma^2_Mt)\n",
    "    process = generator(random_state, size, T)\n",
    "    market_return = process[:,:,0]\n",
    "    process_aug = torch.cat((beta[:N]*(market_return[:,:,numpy.newaxis]-rf) + rf,process),axis=-1,)\n",
    "    return process_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy\n",
    "from statistics_ import rand_int,check_random_state\n",
    "from exception import SampleSizeError,DistributionError\n",
    "from measure import Expectation\n",
    "import copy_ as deepcopy\n",
    "from collections import abc\n",
    "from numbers import Number\n",
    "import time\n",
    "import math\n",
    "\n",
    "class StochasticModel(object):\n",
    "    \"\"\"The StochasticModel class\"\"\"\n",
    "    def __init__(self, name=\"\"):\n",
    "        self._model = gurobipy.Model(env=gurobipy.Env(), name=name)\n",
    "        # each and every instance must have state variables, local copy variables\n",
    "        self.states = []\n",
    "        self.local_copies = []\n",
    "        # (discretized) uncertainties\n",
    "        # stage-wise independent discrete uncertainties\n",
    "        self.uncertainty_rhs = {}\n",
    "        self.uncertainty_coef = {}\n",
    "        self.uncertainty_obj = {}\n",
    "        # indices of stage-dependent uncertainties\n",
    "        self.uncertainty_rhs_dependent = {}\n",
    "        self.uncertainty_coef_dependent = {}\n",
    "        self.uncertainty_obj_dependent = {}\n",
    "        # true uncertainties\n",
    "        # stage-wise independent true continuous uncertainties\n",
    "        self.uncertainty_rhs_continuous = {}\n",
    "        self.uncertainty_coef_continuous = {}\n",
    "        self.uncertainty_obj_continuous = {}\n",
    "        self.uncertainty_mix_continuous = {}\n",
    "        # stage-wise independent true discrete uncertainties\n",
    "        self.uncertainty_rhs_discrete = {}\n",
    "        self.uncertainty_coef_discrete = {}\n",
    "        self.uncertainty_obj_discrete = {}\n",
    "        # cutting planes approximation of recourse variable alpha\n",
    "        self.alpha = None\n",
    "        self.cuts = []\n",
    "        # linking constraints\n",
    "        self.link_constrs = []\n",
    "        # number of discrete uncertainties\n",
    "        self.n_samples = 1\n",
    "        # number of state varibles\n",
    "        self.n_states = 0\n",
    "        # probability measure for discrete uncertainties\n",
    "        self.probability = None\n",
    "        # type of true problem: continuous/discrete\n",
    "        self._type = None\n",
    "        # flag to indicate discretization of true problem\n",
    "        self._flag_discrete = 0\n",
    "        # collection of all specified dim indices of Markovian uncertainties\n",
    "        self.Markovian_dim_index = []\n",
    "        # risk measure\n",
    "        self.measure = Expectation\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            return getattr(self._model, name)\n",
    "        except AttributeError:\n",
    "            raise AttributeError(\"no attribute named {}\".format(name))\n",
    "\n",
    "    def addStateVars(self,*indices,lb=0.0,ub=1e+100,obj=0.0,vtype='C',name=\"\",uncertainty=None,uncertainty_dependent=None):\n",
    "        # Add state variables in bulk. Generalize gurobipy.addVars() to\n",
    "        # incorporate uncertainty in the objective function. Variables are added\n",
    "        # as state variables and the corresponding local copy variables will be\n",
    "        # added behind the scene\n",
    "        state = self._model.addVars(*indices, lb=lb, ub=ub, obj=obj, vtype=vtype, name=name)\n",
    "        local_copy = self._model.addVars(*indices, lb=lb, ub=ub, name=name + \"_local_copy\")\n",
    "        self._model.update()\n",
    "        self.states += state.values()\n",
    "        self.local_copies += local_copy.values()\n",
    "        self.n_states += len(state)\n",
    "\n",
    "        if uncertainty is not None:\n",
    "            uncertainty = self._check_uncertainty(uncertainty, 0, len(state))\n",
    "            if callable(uncertainty):\n",
    "                self.uncertainty_obj_continuous[tuple(state.values())] = uncertainty\n",
    "            else:\n",
    "                self.uncertainty_obj[tuple(state.values())] = uncertainty\n",
    "\n",
    "        if uncertainty_dependent is not None:\n",
    "            uncertainty_dependent = self._check_uncertainty_dependent(uncertainty_dependent, 0, len(state))\n",
    "            self.uncertainty_obj_dependent[tuple(state.values())] = uncertainty_dependent\n",
    "\n",
    "        return state, local_copy\n",
    "    \n",
    "    def addStateVar(self,lb=0.0,ub=1e+100,obj=0.0,vtype='C',name=\"\",column=None,uncertainty=None,uncertainty_dependent=None,):\n",
    "        # Add a state variable to the model. Generalize gurobipy.addVar() to\n",
    "        # incorporate uncertainty in the objective function. The variable is added\n",
    "        # as a state variable and the corresponding local copy variable will be\n",
    "        # added behind the scene\n",
    "\n",
    "        state = self._model.addVar(lb=lb, ub=ub, obj=obj, vtype=vtype, name=name, column=column,)\n",
    "        local_copy = self._model.addVar(name=name+\"_local_copy\", lb=lb, ub=ub,)\n",
    "        self._model.update()\n",
    "        self.states += [state]\n",
    "        self.local_copies += [local_copy]\n",
    "        self.n_states += 1\n",
    "\n",
    "        if uncertainty is not None:\n",
    "            uncertainty = self._check_uncertainty(uncertainty, 0, 1)\n",
    "            if callable(uncertainty):\n",
    "                self.uncertainty_obj_continuous[state] = uncertainty\n",
    "            else:\n",
    "                self.uncertainty_obj[state] = uncertainty\n",
    "\n",
    "        if uncertainty_dependent is not None:\n",
    "            uncertainty_dependent = self._check_uncertainty_dependent(uncertainty_dependent, 0, 1)\n",
    "            self.uncertainty_obj_dependent[state] = uncertainty_dependent\n",
    "\n",
    "        return state, local_copy\n",
    "\n",
    "    def addVars(self,*indices,lb=0.0,ub=1e+100,obj=0.0,vtype='C',name=\"\",uncertainty=None,uncertainty_dependent=None):\n",
    "        # Add variables in bulk. Generalize gurobipy.addVars() to\n",
    "        # incorporate uncertainty in the objective function\n",
    "\n",
    "        var = self._model.addVars(*indices, lb=lb, ub=ub, obj=obj, vtype=vtype, name=name)\n",
    "        self._model.update()\n",
    "\n",
    "        if uncertainty is not None:\n",
    "            uncertainty = self._check_uncertainty(uncertainty, 0, len(var))\n",
    "            if callable(uncertainty):\n",
    "                self.uncertainty_obj_continuous[tuple(var.values())] = uncertainty\n",
    "            else:\n",
    "                self.uncertainty_obj[tuple(var.values())] = uncertainty\n",
    "\n",
    "        if uncertainty_dependent is not None:\n",
    "            uncertainty_dependent = self._check_uncertainty_dependent(uncertainty_dependent, 0, len(var))\n",
    "            self.uncertainty_obj_dependent[tuple(var.values())] = uncertainty_dependent\n",
    "\n",
    "        return var\n",
    "    \n",
    "    def addConstrs(self, generator, name=\"\", uncertainty=None, uncertainty_dependent=None):\n",
    "        # to incorporate uncertainty on the RHS of the constraints.\n",
    "        # If you want to add constraints with uncertainties on coefficients,\n",
    "        # use addConstr() instead and add those constraints one by one\n",
    "        constr = self._model.addConstrs(generator, name=name)\n",
    "        self._model.update()\n",
    "\n",
    "        if uncertainty is not None:\n",
    "            uncertainty = self._check_uncertainty(uncertainty, 0, len(constr))\n",
    "            if callable(uncertainty):\n",
    "                self.uncertainty_rhs_continuous[tuple(constr.values())] = uncertainty\n",
    "            else:\n",
    "                self.uncertainty_rhs[tuple(constr.values())] = uncertainty\n",
    "\n",
    "        if uncertainty_dependent is not None:\n",
    "            uncertainty_dependent = self._check_uncertainty_dependent(uncertainty_dependent, 0, len(constr))\n",
    "            self.uncertainty_rhs_dependent[tuple(constr.values())] = uncertainty_dependent\n",
    "\n",
    "        return constr\n",
    "    \n",
    "    def addConstr(self,lhs,sense=None,rhs=None,name=\"\",uncertainty=None,uncertainty_dependent=None,):\n",
    "        # Add a constraint to the model. Generalize gurobipy.addConstr()\n",
    "        # to incorporate uncertainty in a constraint\n",
    "        constr = self._model.addConstr(lhs, sense=sense, rhs=rhs, name=name)\n",
    "        self._model.update()\n",
    "\n",
    "        if uncertainty is not None:\n",
    "            uncertainty = self._check_uncertainty(uncertainty, 1, 1)\n",
    "            for key, value in uncertainty.items():\n",
    "                # key can be a gurobipy.Var or \"rhs\"\n",
    "                # Append constr to the key\n",
    "                if type(key) == gurobipy.Var:\n",
    "                    if callable(value):\n",
    "                        self.uncertainty_coef_continuous[(constr, key)] = value\n",
    "                    else:\n",
    "                        self.uncertainty_coef[(constr, key)] = value\n",
    "                elif type(key) == str and key.lower() == \"rhs\":\n",
    "                    if callable(value):\n",
    "                        self.uncertainty_rhs_continuous[constr] = value\n",
    "                    else:\n",
    "                        self.uncertainty_rhs[constr] = value\n",
    "                else:\n",
    "                    raise ValueError(\"wrong uncertainty key!\")\n",
    "\n",
    "        if uncertainty_dependent is not None:\n",
    "            uncertainty_dependent = self._check_uncertainty_dependent(uncertainty_dependent, 1, 1)\n",
    "            for key, value in uncertainty_dependent.items():\n",
    "                # key can be a gurobipy.Var or \"rhs\"\n",
    "                # Append constr to the key\n",
    "                if type(key) == gurobipy.Var:\n",
    "                    if not any(key is item for item in self._model.getVars()):\n",
    "                        raise ValueError(\"wrong uncertainty key!\")\n",
    "                    self.uncertainty_coef_dependent[(constr, key)] = value\n",
    "                elif type(key) == str and key.lower() == \"rhs\":\n",
    "                    self.uncertainty_rhs_dependent[constr] = value\n",
    "                else:\n",
    "                    raise ValueError(\"wrong uncertainty key!\")\n",
    "\n",
    "        return constr\n",
    "    \n",
    "    def _check_uncertainty_dependent(self, uncertainty_dependent, flag_dict, list_dim):\n",
    "        # Make sure the input uncertainty location index is in the correct form.\n",
    "        # Return a copied uncertainty to avoid making changes to mutable object\n",
    "        # given by the users.\n",
    "        if isinstance(uncertainty_dependent, abc.Mapping):\n",
    "            if flag_dict == 0:\n",
    "                raise TypeError(\"wrong uncertainty_dependent format!\")\n",
    "            for key, item in uncertainty_dependent.items():\n",
    "                try:\n",
    "                    item = int(item)\n",
    "                    uncertainty_dependent[key] = item\n",
    "                except (TypeError,ValueError):\n",
    "                    raise ValueError(\"location index of individual component of uncertainty_dependent must be integer!\")\n",
    "                self.Markovian_dim_index.append(item)\n",
    "\n",
    "        elif isinstance(uncertainty_dependent, (abc.Sequence, torch.Tensor)):\n",
    "            uncertainty_dependent = list(uncertainty_dependent)\n",
    "            if len(uncertainty_dependent) != list_dim:\n",
    "                raise ValueError(\"dimension of the scenario is {} while dimension of added object is {}!\".format(len(uncertainty_dependent), list_dim))\n",
    "            self.Markovian_dim_index += uncertainty_dependent\n",
    "\n",
    "        elif isinstance(uncertainty_dependent, Number):\n",
    "            uncertainty_dependent = int(uncertainty_dependent)\n",
    "            if list_dim != 1:\n",
    "                raise ValueError(\"dimension of the scenario is 1 while dimension of added object is {}!\".format(list_dim))\n",
    "            self.Markovian_dim_index.append(uncertainty_dependent)\n",
    "        else:\n",
    "            raise TypeError(\"wrong uncertainty_dependent format\")\n",
    "        return uncertainty_dependent\n",
    "    \n",
    "    def _check_uncertainty(self, uncertainty, flag_dict, list_dim):\n",
    "        # Make sure the input uncertainty is in the correct form. Return a\n",
    "        # copied uncertainty to avoid making changes to mutable object given by\n",
    "        # the users.\n",
    "        if isinstance(uncertainty, abc.Mapping):\n",
    "            uncertainty = dict(uncertainty)\n",
    "            for key, item in uncertainty.items():\n",
    "                if callable(item):\n",
    "                    if not self._type:\n",
    "                        # add uncertainty for the first time\n",
    "                        self._type = \"continuous\"\n",
    "                    else:\n",
    "                        # already added uncertainty\n",
    "                        if self._type != \"continuous\":\n",
    "                            raise SampleSizeError(self._model.modelName,self.n_samples,uncertainty,\"infinite\")\n",
    "                    try:\n",
    "                        item(numpy.random)\n",
    "                    except TypeError:\n",
    "                        raise DistributionError(arg=False)\n",
    "                    try:\n",
    "                        float(item(numpy.random))\n",
    "                    except (ValueError,TypeError):\n",
    "                        raise DistributionError(ret=False)\n",
    "                else:\n",
    "                    try:\n",
    "                        item = torch.tensor(item, dtype=torch.float64)\n",
    "                    except ValueError:\n",
    "                        raise ValueError(\"Scenarios must only contains numbers!\")\n",
    "                    if item.ndim != 1:\n",
    "                        raise ValueError(\"dimension of the distribution is {} while dimension of the added object is {}!\".format(item.ndim, 1))\n",
    "                    uncertainty[key] = list(item)\n",
    "\n",
    "                    if not self._type:\n",
    "                        # add uncertainty for the first time\n",
    "                        self._type = \"discrete\"\n",
    "                        self.n_samples = len(item)\n",
    "                    else:\n",
    "                        # already added uncertainty\n",
    "                        if self._type != \"discrete\":\n",
    "                            raise SampleSizeError(self._model.modelName,\"infinite\",{key:item},len(item))\n",
    "                        if self.n_samples != len(item):\n",
    "                            raise SampleSizeError(self._model.modelName,self.n_samples,{key:item},len(item))\n",
    "            if flag_dict == 0:\n",
    "                raise TypeError(\"wrong uncertainty format!\")\n",
    "        elif isinstance(uncertainty, abc.Callable):\n",
    "            try:\n",
    "                sample = uncertainty(numpy.random)\n",
    "            except TypeError:\n",
    "                raise DistributionError(arg=False)\n",
    "            if list_dim == 1:\n",
    "                try:\n",
    "                    float(sample)\n",
    "                except (ValueError,TypeError):\n",
    "                    raise DistributionError(ret=False)\n",
    "            else:\n",
    "                try:\n",
    "                    sample = [float(item) for item in sample]\n",
    "                except (ValueError,TypeError):\n",
    "                    raise DistributionError(ret=False)\n",
    "                if list_dim != len(uncertainty(numpy.random)):\n",
    "                    raise ValueError(\n",
    "                        \"dimension of the distribution is {} while dimension of the added object is {}!\".format(len(uncertainty(numpy.random)), list_dim))\n",
    "            if not self._type:\n",
    "                # add uncertainty for the first time\n",
    "                self._type = \"continuous\"\n",
    "            else:\n",
    "                # already added uncertainty\n",
    "                if self._type != \"continuous\":\n",
    "                    raise SampleSizeError(self._model.modelName,self.n_samples,uncertainty,\"infinite\")\n",
    "        elif isinstance(uncertainty, (abc.Sequence, torch.Tensor)):\n",
    "            uncertainty = torch.tensor(uncertainty)\n",
    "            if list_dim == 1:\n",
    "                if uncertainty.ndim != 1:\n",
    "                    raise ValueError(\"dimension of the scenarios is {} while dimension of the added object is 1!\".format(uncertainty.ndim))\n",
    "                try:\n",
    "                    uncertainty = [float(item) for item in uncertainty]\n",
    "                except ValueError:\n",
    "                    raise ValueError(\"Scenarios must only contains numbers!\")\n",
    "            else:\n",
    "                # list to list\n",
    "                if uncertainty.ndim != 2 or uncertainty.shape[1] != list_dim:\n",
    "                    dim = None if uncertainty.ndim == 1 else uncertainty.shape[1]\n",
    "                    raise ValueError(\"dimension of the scenarios is {} while dimension of the added object is 1!\".format(dim, uncertainty.ndim))\n",
    "                try:\n",
    "                    uncertainty = torch.tensor(uncertainty, dtype=torch.float64)\n",
    "                except ValueError:\n",
    "                    raise ValueError(\"Scenarios must only contains numbers!\")\n",
    "                uncertainty = [list(item) for item in uncertainty]\n",
    "            if not self._type:\n",
    "                self._type = \"discrete\"\n",
    "                self.n_samples = len(uncertainty)\n",
    "            else:\n",
    "                if self._type != \"discrete\":\n",
    "                    raise SampleSizeError(self._model.modelName,\"infinite\",uncertainty,len(uncertainty))\n",
    "                if self.n_samples != len(uncertainty):\n",
    "                    raise SampleSizeError(self._model.modelName,self.n_samples,uncertainty,len(uncertainty))\n",
    "        else:\n",
    "            raise TypeError(\"wrong uncertainty format!\")\n",
    "\n",
    "        return uncertainty\n",
    "    \n",
    "    def _discretize(self, n_samples, random_state, replace=True):\n",
    "        # Discretize stage-wise independent continuous uncertainties.\n",
    "        if hasattr(self,'_flag_discrete') and self._flag_discrete == 1: return\n",
    "        # Discretize continuous true problem\n",
    "        if self._type == \"continuous\":\n",
    "            self.n_samples = n_samples\n",
    "            # Order of discretization matters\n",
    "            for key, dist in sorted(self.uncertainty_rhs_continuous.items(),key=lambda t: repr(t[0]),):\n",
    "                self.uncertainty_rhs[key] = [dist(random_state) for _ in range(self.n_samples)]\n",
    "            for key, dist in sorted(self.uncertainty_obj_continuous.items(),key=lambda t: repr(t[0]),):\n",
    "                self.uncertainty_obj[key] = [dist(random_state) for _ in range(self.n_samples)]\n",
    "            for key, dist in sorted(self.uncertainty_coef_continuous.items(),key=lambda t: repr(t[0]),):\n",
    "                self.uncertainty_coef[key] = [dist(random_state) for _ in range(self.n_samples)]\n",
    "            for keys, dist in sorted(self.uncertainty_mix_continuous.items(),key=lambda t: repr(t[0]),):\n",
    "                for i in range(self.n_samples):\n",
    "                    sample = dist(random_state)\n",
    "                    for index, key in enumerate(keys):\n",
    "                        if type(key) == gurobipy.Var:\n",
    "                            if key not in self.uncertainty_obj.keys():\n",
    "                                self.uncertainty_obj[key] = [sample[index]]\n",
    "                            else:\n",
    "                                self.uncertainty_obj[key].append(sample[index])\n",
    "                        elif type(key) == gurobipy.Constr:\n",
    "                            if key not in self.uncertainty_rhs.keys():\n",
    "                                self.uncertainty_rhs[key] = [sample[index]]\n",
    "                            else:\n",
    "                                self.uncertainty_rhs[key].append(sample[index])\n",
    "                        else:\n",
    "                            if key not in self.uncertainty_coef.keys():\n",
    "                                self.uncertainty_coef[key] = [sample[index]]\n",
    "                            else:\n",
    "                                self.uncertainty_coef[key].append(sample[index])\n",
    "        # Discretize discrete true problem\n",
    "        else:\n",
    "            if n_samples > self.n_samples:\n",
    "                raise Exception(\"n_samples should be smaller than the total number of samples!\")\n",
    "            for key, samples in sorted(self.uncertainty_rhs.items(), key=lambda t: repr(t[0])):\n",
    "                self.uncertainty_rhs_discrete[key] = samples\n",
    "                # numpy.random.choice does not work on multi-dimensional arrays\n",
    "                drawed_indices = rand_int(self.n_samples,random_state,size=n_samples,probability=self.probability,replace=replace,)\n",
    "                self.uncertainty_rhs[key] = [samples[index] for index in drawed_indices]\n",
    "            for key, samples in sorted(self.uncertainty_obj.items(), key=lambda t: repr(t[0])):\n",
    "                self.uncertainty_obj_discrete[key] = samples\n",
    "                drawed_indices = rand_int(self.n_samples,random_state,size=n_samples,probability=self.probability,replace=replace,)\n",
    "                self.uncertainty_obj[key] = [samples[index] for index in drawed_indices]\n",
    "            for key, samples in sorted(self.uncertainty_coef.items(), key=lambda t: repr(t[0])):\n",
    "                self.uncertainty_coef_discrete[key] = samples\n",
    "                drawed_indices = rand_int(self.n_samples,random_state,size=n_samples,probability=self.probability,replace=replace,)\n",
    "                self.uncertainty_coef[key] = [samples[index] for index in drawed_indices]\n",
    "            self.n_samples_discrete = self.n_samples\n",
    "            self.n_samples = n_samples\n",
    "        self._flag_discrete = 1\n",
    "\n",
    "    def _set_up_CTG(self, discount, bound):\n",
    "        # if it's a minimization problem, we need a lower bound for alpha\n",
    "        if self.modelsense == 1:\n",
    "            if self.alpha is None:\n",
    "                self.alpha = self._model.addVar(lb=bound,ub=gurobipy.GRB.INFINITY,obj=discount,name=\"alpha\",)\n",
    "        # if it's a maximation problem, we need an upper bound for alpha\n",
    "        else:\n",
    "            if self.alpha is None:\n",
    "                self.alpha = self._model.addVar(ub=bound,lb=-gurobipy.GRB.INFINITY,obj=discount,name=\"alpha\",)\n",
    "\n",
    "    def _delete_link_constrs(self):\n",
    "        if self.link_constrs != []:\n",
    "            for constr in self.link_constrs:\n",
    "                self._model.remove(constr)\n",
    "            self.link_constrs = []\n",
    "\n",
    "    def _set_up_link_constrs(self):\n",
    "        if self.link_constrs == []:\n",
    "            self.link_constrs = list(self._model.addConstrs((var == var.lb for var in self.local_copies),name=\"link_constrs\",).values())\n",
    "\n",
    "    def _update_uncertainty_dependent(self, Markov_state):\n",
    "        # Update model with a Markov state\n",
    "        if self.uncertainty_coef_dependent is not None:\n",
    "            for (constr,var), value in self.uncertainty_coef_dependent.items():\n",
    "                self._model.chgCoeff(constr, var, Markov_state[value])\n",
    "        if self.uncertainty_rhs_dependent is not None:\n",
    "            for constr_tuple, value in self.uncertainty_rhs_dependent.items():\n",
    "                if type(constr_tuple) == tuple:\n",
    "                    self._model.setAttr(\"RHS\",list(constr_tuple),[Markov_state[i] for i in value],)\n",
    "                else:\n",
    "                    constr_tuple.setAttr(\"RHS\", Markov_state[value])\n",
    "        if self.uncertainty_obj_dependent is not None:\n",
    "            for var_tuple, value in self.uncertainty_obj_dependent.items():\n",
    "                if type(var_tuple) == tuple:\n",
    "                    self._model.setAttr(\"Obj\",list(var_tuple),[Markov_state[i] for i in value],)\n",
    "                else:\n",
    "                    var_tuple.setAttr(\"Obj\", Markov_state[value])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics_ import check_Markovian_uncertainty, check_Markov_states_and_transition_matrix\n",
    "from exception import MarkovianDimensionError\n",
    "import numbers\n",
    "\n",
    "\n",
    "class MSLP(object):\n",
    "    # A multistage stochastic linear program composed of a sequence of StochasticModels.\n",
    "    def __init__(self,size,T,bound=None,sense=1,outputFlag=0,discount=1.0,ctg=False,**kwargs):\n",
    "        if (T < 2 or discount > 1 or discount < 0 or sense not in [-1, 1] or outputFlag not in [0, 1]):\n",
    "            raise Exception('Arguments of SDDP construction are not valid!')\n",
    "\n",
    "        self.T = T\n",
    "        self.size = size\n",
    "        self.discount = discount\n",
    "        self.bound = bound\n",
    "        self.sense = sense\n",
    "        self.n_Markov_states = 1\n",
    "        self.dim_Markov_states = {}\n",
    "        self.measure = 'risk neutral'\n",
    "        self._type = 'stage-wise independent'\n",
    "        self._individual_type = 'original'\n",
    "        self._set_up_default_bound()\n",
    "        self._set_up_model()\n",
    "        self._set_up_model_attr(sense, outputFlag, kwargs)\n",
    "        self._flag_discrete = 0\n",
    "        self._flag_update = 0\n",
    "        self.db = None\n",
    "        self._flag_infinity = 0\n",
    "        if ctg: self._set_up_CTG()\n",
    "        self.n_states = None\n",
    "        self.n_samples = None\n",
    "\n",
    "    def __getitem__(self, t):\n",
    "        return self.models[t]\n",
    "\n",
    "    def _set_up_default_bound(self):\n",
    "        if self.bound is None:\n",
    "            self.bound = -1000000000 if self.sense == 1 else 1000000000\n",
    "\n",
    "    def _set_up_model(self):\n",
    "        self.models = [StochasticModel(name=str(t)) for t in range(self.T)]\n",
    "\n",
    "    def _set_up_model_attr(self, sense, outputFlag, kwargs):\n",
    "        for t in range(self.T):\n",
    "            m = self.models[t]\n",
    "            m.Params.outputFlag = outputFlag\n",
    "            m.setAttr('modelsense', sense)\n",
    "            for k,v in kwargs.items():\n",
    "                m.setParam(k,v)\n",
    "\n",
    "    def add_Markovian_uncertainty(self, Markovian_uncertainty):\n",
    "        # Add a Markovian continuous process.\n",
    "\n",
    "        if hasattr(self, \"Markovian_uncertainty\") or hasattr(self,\"Markov_states\"):\n",
    "            raise ValueError(\"Markovian uncertainty has already added!\")\n",
    "        self.dim_Markov_states=check_Markovian_uncertainty(Markovian_uncertainty,self.size,self.T)\n",
    "        self.Markovian_uncertainty = Markovian_uncertainty\n",
    "        self._type = 'Markovian'\n",
    "\n",
    "    def discretize(self,n_samples=None,random_state=None,replace=True,n_Markov_states=None,method='SA',n_sample_paths=None,Markov_states=None,transition_matrix=None,int_flag=0):\n",
    "        # Discretize Markovian continuous uncertainty by k-means or (robust)\n",
    "        # stochasitic approximation.\n",
    "        if n_samples is not None:\n",
    "            if isinstance(n_samples, (numbers.Integral, torch.int)):\n",
    "                if n_samples < 1:\n",
    "                    raise ValueError(\"n_samples should be bigger than zero!\")\n",
    "                n_samples = ([1] + [n_samples] * (self.T-1))\n",
    "            elif isinstance(n_samples, (abc.Sequence, torch.Tensor)):\n",
    "                if len(n_samples) != self.T:\n",
    "                    raise ValueError(\"n_samples list should be of length {} rather than {}!\".format(self.T,len(n_samples)))\n",
    "                if n_samples[0] != 1:\n",
    "                    raise ValueError(\"The first stage model should be deterministic!\")\n",
    "            else:\n",
    "                raise ValueError(\"Invalid input of n_samples!\")\n",
    "            # discretize stage-wise independent continuous distribution\n",
    "            random_state = check_random_state(random_state)\n",
    "            for t in range(1,self.T):\n",
    "                self.models[t]._discretize(n_samples[t],random_state,replace)\n",
    "        if n_Markov_states is None and method != 'input': return\n",
    "        if method == 'input' and (Markov_states is None or transition_matrix is None): \n",
    "            return\n",
    "        if n_Markov_states is not None:\n",
    "            if isinstance(n_Markov_states, (numbers.Integral, torch.Tensor)):\n",
    "                if n_Markov_states < 1:\n",
    "                    raise ValueError(\"n_Markov_states should be bigger than zero!\")\n",
    "                n_Markov_states = ([1] + [n_Markov_states] * (self.T-1))\n",
    "            elif isinstance(n_Markov_states, (abc.Sequence, torch.Tensor)):\n",
    "                if len(n_Markov_states) != self.T:\n",
    "                    raise ValueError(\"n_Markov_states list should be of length {} rather than {}!\".format(self.T,len(n_Markov_states)))\n",
    "                if n_Markov_states[0] != 1:\n",
    "                    raise ValueError(\"The first stage model should be deterministic!\")\n",
    "            else:\n",
    "                raise ValueError(\"Invalid input of n_Markov_states!\")\n",
    "        from discretize import MarkovSampler\n",
    "        if method in ['RSA','SA','SAA']:\n",
    "            markovian = MarkovSampler(f=self.Markovian_uncertainty,n_Markov_states=n_Markov_states,n_sample_paths=n_sample_paths,int_flag=int_flag,)\n",
    "        if method in ['RSA','SA','SAA']:\n",
    "            self.Markov_states,self.transition_matrix = getattr(markovian, method)()\n",
    "        elif method == 'input':\n",
    "            dim_Markov_states, n_Markov_states = (check_Markov_states_and_transition_matrix(Markov_states=Markov_states,transition_matrix=transition_matrix,T=self.T,))\n",
    "            if dim_Markov_states != self.dim_Markov_states:\n",
    "                raise ValueError(\"The dimension of the given sample path \" + \"generator is not the same as the given Markov chain \" + \"approximation!\")\n",
    "            self.Markov_states = Markov_states\n",
    "            self.transition_matrix = [torch.tensor(item) for item in transition_matrix]\n",
    "        self._flag_discrete = 1\n",
    "        self.n_Markov_states = n_Markov_states\n",
    "        if method in ['RSA','SA','SAA']:\n",
    "            return markovian\n",
    "        \n",
    "    def _set_up_CTG(self):\n",
    "        for t in range(self.T-1):\n",
    "            self._set_up_CTG_for_t(t)\n",
    "\n",
    "    def _set_up_CTG_for_t(self, t):\n",
    "        M = ([self.models[t]] if type(self.models[t]) != list else self.models[t])\n",
    "        for m in M:\n",
    "            m._set_up_CTG(discount=self.discount, bound=self.bound)\n",
    "            m.update()\n",
    "\n",
    "    def set_AVaR(self, l, a, method='indirect'):\n",
    "        # Set linear combination of expectation and conditional value at risk\n",
    "        # (average value at risk) as risk measure\n",
    "\n",
    "        if isinstance(l, (abc.Sequence, numpy.ndarray)):\n",
    "            if len(l) not in [self.T-1, self.T]:\n",
    "                raise ValueError(\"Length of l must be T-1/T!\")\n",
    "            if not all(item <= 1 and item >= 0 for item in l):\n",
    "                raise ValueError(\"l must be between 0 and 1!\")\n",
    "            l = [None] + list(l)\n",
    "        elif isinstance(l, (numbers.Number)):\n",
    "            if l > 1 or l < 0:\n",
    "                raise ValueError(\"l must be between 0 and 1!\")\n",
    "            l = [None] + [l] * (self.T-1)\n",
    "        else:\n",
    "            raise TypeError(\"l should be float/array-like instead of {}!\".format(type(l)))\n",
    "        if isinstance(a, (abc.Sequence, numpy.ndarray)):\n",
    "            if len(a) not in [self.T-1, self.T]:\n",
    "                raise ValueError(\"Length of a must be T-1!\")\n",
    "            if not all(item <= 1 and item >= 0 for item in a):\n",
    "                raise ValueError(\"a must be between 0 and 1!\")\n",
    "            a = [None] + list(a)\n",
    "        elif isinstance(a, (numbers.Number)):\n",
    "            if a > 1 or a < 0:\n",
    "                raise ValueError(\"a must be between 0 and 1!\")\n",
    "            a = [None] + [a] * (self.T-1)\n",
    "        else:\n",
    "            raise TypeError(\"a should be float/array-like instead of {}!\".format(type(a)))\n",
    "        \n",
    "        self.a = a\n",
    "        self.l = l\n",
    "\n",
    "        if method == 'direct':\n",
    "            self._set_up_CTG()\n",
    "            from measure import Expectation_AVaR\n",
    "            from functools import partial\n",
    "            for t in range(1, self.T):\n",
    "                M = (self.models[t] if type(self.models[t]) == list else [self.models[t]])\n",
    "                for m in M:\n",
    "                    m.measure = partial(Expectation_AVaR,a=a[t], l=l[t])\n",
    "            for t in range(self.T):\n",
    "                M = (self.models[t] if type(self.models[t]) == list else [self.models[t]])\n",
    "                for m in M:\n",
    "                    stage_cost = m.addVar(name=\"stage_cost\",lb=-gurobipy.GRB.INFINITY,ub=gurobipy.GRB.INFINITY,)\n",
    "                    alpha = m.alpha if m.alpha is not None else 0.0\n",
    "                    m.addConstr(m.getObjective() - self.discount*alpha == stage_cost)\n",
    "                    m.update()\n",
    "\n",
    "\n",
    "        elif method == 'indirect':\n",
    "            self._set_up_CTG()\n",
    "            self._delete_link_constrs()\n",
    "            for t in range(self.T):\n",
    "                M = (self.models[t] if type(self.models[t]) == list else [self.models[t]])\n",
    "                for m in M:\n",
    "                    p_now, p_past = m.addStateVar(lb=-gurobipy.GRB.INFINITY,ub=gurobipy.GRB.INFINITY,name=\"additional_state\",)\n",
    "                    v = m.addVar(name=\"additional_var\")\n",
    "                    m.addConstr(self.sense * (p_now-self.bound) >= 0)\n",
    "                    z = m.getObjective()\n",
    "                    stage_cost = m.addVar(name=\"stage_cost\",lb=-gurobipy.GRB.INFINITY,ub=gurobipy.GRB.INFINITY,)\n",
    "                    alpha = m.alpha if m.alpha is not None else 0.0\n",
    "                    if t > 0:\n",
    "                        if m.uncertainty_obj != {}:\n",
    "                            m.addConstr(z - self.discount*alpha == stage_cost,uncertainty=m.uncertainty_obj,)\n",
    "                            m.uncertainty_obj = {}\n",
    "                            m.setObjective((1 - l[t]) * (stage_cost + self.discount * alpha) + l[t] * p_past + self.sense * l[t] / a[t] * v)\n",
    "                            m.addConstr(v >= (stage_cost + self.discount * alpha - p_past) * self.sense)\n",
    "                        else:\n",
    "                            m.addConstr(z - self.discount*alpha == stage_cost)\n",
    "                            m.setObjective((1-l[t]) * z + l[t] * p_past + self.sense * l[t] / a[t] * v)\n",
    "                            m.addConstr(v >= (z - p_past) * self.sense)\n",
    "                    else:\n",
    "                        m.addConstr(z - self.discount*alpha == stage_cost)\n",
    "                    m.update()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        self.measure = \"risk averse\"\n",
    "\n",
    "    def _delete_link_constrs(self):\n",
    "        # model copies may not be ready while state size may have changed\n",
    "        for t in range(1, self.T):\n",
    "            M = (\n",
    "                self.models[t]\n",
    "                if type(self.models[t]) == list\n",
    "                else [self.models[t]]\n",
    "            )\n",
    "            for m in M:\n",
    "                m._delete_link_constrs()\n",
    "                m.update()\n",
    "\n",
    "    def _update(self):\n",
    "        self._check_first_stage_model()\n",
    "        self._check_inidividual_Markovian_index()\n",
    "        self._check_individual_stage_models()\n",
    "        self._set_up_CTG()\n",
    "        self._set_up_link_constrs()\n",
    "        self._check_multistage_model()\n",
    "        self._flag_update = 1\n",
    "\n",
    "    def _check_first_stage_model(self):\n",
    "        # Ensure the first stage model is deterministic. The First stage model\n",
    "        # is only allowed to have uncertainty with length one.\"\"\"\n",
    "        m = self.models[0] if type(self.models[0]) != list else self.models[0][0]\n",
    "        if m.n_samples != 1:\n",
    "            raise Exception(\"First stage must be deterministic!\")\n",
    "        \n",
    "    def _check_inidividual_Markovian_index(self):\n",
    "        \"\"\"Check dimension indices of sample path generator are set properly.\"\"\"\n",
    "        for t in range(self.T):\n",
    "            M = (\n",
    "                self.models[t]\n",
    "                if type(self.models[t]) == list\n",
    "                else [self.models[t]]\n",
    "            )\n",
    "            for m in M:\n",
    "                if m.Markovian_dim_index != []:\n",
    "                    if any(index not in range(self.dim_Markov_states[t])\n",
    "                            for index in m.Markovian_dim_index):\n",
    "                        raise MarkovianDimensionError\n",
    "                    \n",
    "    def _check_individual_stage_models(self):\n",
    "        \"\"\"Check state variables are set properly. Check stage-wise continuous\n",
    "        uncertainties are discretized.\"\"\"\n",
    "        m = self.models[0] if type(self.models[0]) != list else self.models[0][0]\n",
    "        if m.states == []:\n",
    "            raise Exception(\"State variables must be set!\")\n",
    "        n_states = m.n_states\n",
    "        for t in range(1, self.T):\n",
    "            M = (self.models[t] if type(self.models[t]) == list else [self.models[t]])\n",
    "            for m in M:\n",
    "                if m._type == \"continuous\":\n",
    "                    if m._flag_discrete == 0:\n",
    "                        raise Exception(\"Stage-wise independent continuous uncertainties \"+\"must be discretized!\")\n",
    "                    self._individual_type = \"discretized\"\n",
    "                else:\n",
    "                    if m._flag_discrete == 1:\n",
    "                        self._individual_type = \"discretized\"\n",
    "        if self._type == \"Markovian\" and self._flag_discrete == 0:\n",
    "            raise Exception(\"Stage-wise dependent continuous uncertainties \"+\"must be discretized!\")\n",
    "        \n",
    "    def _set_up_link_constrs(self):\n",
    "        # model copies may not be ready while state size may have changed\n",
    "        for t in range(1, self.T):\n",
    "            M = (\n",
    "                self.models[t]\n",
    "                if type(self.models[t]) == list\n",
    "                else [self.models[t]]\n",
    "            )\n",
    "            for m in M:\n",
    "                m._set_up_link_constrs()\n",
    "                m.update()\n",
    "\n",
    "    def _check_multistage_model(self):\n",
    "        \"\"\"Check Markovian uncertainties are discretized. Copy StochasticModels\n",
    "        for every Markov states.\"\"\"\n",
    "        if self._type == \"Markovian\" and self._flag_discrete == 0:\n",
    "            raise Exception(\"Markovian uncertainties must be discretized!\")\n",
    "        if self._type == \"Markov chain\" or (self._type == \"Markovian\" and self._flag_discrete == 1):\n",
    "            if type(self.models[0]) != list:\n",
    "                models = self.models\n",
    "                self.models = [[None for k in range(self.n_Markov_states[t])] for t in range(self.T)]\n",
    "                for t in range(self.T):\n",
    "                    m = models[t]\n",
    "                    for k in range(self.n_Markov_states[t]):\n",
    "                        m._update_uncertainty_dependent(self.Markov_states[t][k])\n",
    "                        m.update()\n",
    "                        self.models[t][k] = m.copy()\n",
    "        self.n_states = ([self.models[t].n_states for t in range(self.T)] if self._type == 'stage-wise independent' else [self.models[t][0].n_states for t in range(self.T)])\n",
    "        self.n_samples = ([self.models[t].n_samples for t in range(self.T)] if self._type == 'stage-wise independent' else [self.models[t][0].n_samples for t in range(self.T)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Restricted license - for non-production use only - expires 2025-11-24\n"
     ]
    }
   ],
   "source": [
    "import statistics_\n",
    "\n",
    "AssetMgt = MSLP(T=T, size=200, sense=-1, bound=200)\n",
    "AssetMgt.add_Markovian_uncertainty(generator_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(T):\n",
    "    m = AssetMgt[t]\n",
    "    now, past = m.addStateVars(N+1, lb=0, obj=0, name='asset')\n",
    "    if t == 0:\n",
    "        buy = m.addVars(N, name='buy')\n",
    "        sell = m.addVars(N, name='sell')\n",
    "        m.addConstrs(now[j] == buy[j] - sell[j] for j in range(N))\n",
    "        m.addConstr(now[N] == 100 - (1+fee) * gurobipy.quicksum(buy[j] for j in range(N)) + (1-fee) * gurobipy.quicksum(sell[j] for j in range(N)))\n",
    "    elif t != T-1:\n",
    "        sell = m.addVars(N, name='sell')\n",
    "        buy = m.addVars(N, name='buy')\n",
    "        capm = m.addVars(N, lb = -gurobipy.GRB.INFINITY, name='capm')\n",
    "        idio = m.addVars(N, name='idio')\n",
    "        m.addConstr(now[N] == ((1+rf) * past[N] - (1+fee) * gurobipy.quicksum(buy[j] for j in range(N)) + (1-fee) * gurobipy.quicksum(sell[j] for j in range(N))))\n",
    "        m.addConstrs(now[j] == capm[j] + idio[j] + buy[j] - sell[j] for j in range(N))\n",
    "        for j in range(N):\n",
    "            m.addConstr(past[j] == capm[j], uncertainty_dependent={past[j]:j})\n",
    "            m.addConstr(past[j] == idio[j], uncertainty={past[j]:f(alpha[j],sigma[j])})\n",
    "    else:\n",
    "        v = m.addVar(obj=1, lb=-gurobipy.GRB.INFINITY, name='wealth')\n",
    "        capm = m.addVars(N, lb = -gurobipy.GRB.INFINITY, name='capm')\n",
    "        idio = m.addVars(N, name='idio')\n",
    "        m.addConstr(v == gurobipy.quicksum(now[j] for j in range(N+1)))\n",
    "        m.addConstrs(now[j] == capm[j] + idio[j] for j in range(N))\n",
    "        for j in range(N):\n",
    "            m.addConstr(past[j] == capm[j], uncertainty_dependent={past[j]:j})\n",
    "            m.addConstr(past[j] == idio[j], uncertainty={past[j]:f(alpha[j],sigma[j])})\n",
    "        m.addConstr(now[N] == (1+rf) * past[N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'msppy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmsppy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggerSDDP,LoggerEvaluation,LoggerComparison,Logger\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmsppy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstatistics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_random_state,rand_int,compute_CI,allocate_jobs\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmsppy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Evaluation, EvaluationTrue\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'msppy'"
     ]
    }
   ],
   "source": [
    "from msppy.utils.logger import LoggerSDDP,LoggerEvaluation,LoggerComparison,Logger\n",
    "from msppy.utils.statistics import check_random_state,rand_int,compute_CI,allocate_jobs\n",
    "from msppy.evaluation import Evaluation, EvaluationTrue\n",
    "import time\n",
    "import numpy\n",
    "import multiprocessing\n",
    "import gurobipy\n",
    "import numbers\n",
    "from collections import abc\n",
    "import pandas\n",
    "import math\n",
    "\n",
    "\n",
    "class SDDP(object):\n",
    "    \"\"\"\n",
    "    SDDP solver base class.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    MSP: list\n",
    "        A multi-stage stochastic program object.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, MSP,biased_sampling = False):\n",
    "        self.db = []\n",
    "        self.pv = []\n",
    "        self.MSP = MSP\n",
    "        self.forward_T = MSP.T\n",
    "        self.cut_T = MSP.T - 1\n",
    "        self.cut_type = [\"B\"]\n",
    "        self.cut_type_list = [[\"B\"] for t in range(self.cut_T)]\n",
    "        self.iteration = 0\n",
    "        self.n_processes = 1\n",
    "        self.n_steps = 1\n",
    "        self.percentile = 95\n",
    "        self.biased_sampling = biased_sampling\n",
    "\n",
    "        if self.biased_sampling:\n",
    "            try:\n",
    "                self.a = self.MSP.a\n",
    "                self.l = self.MSP.l\n",
    "                for t in range(self.MSP.T):\n",
    "                    m = self.MSP.models[t]\n",
    "                    n_samples = m.n_samples\n",
    "                    m.counts = numpy.zeros(n_samples)\n",
    "                    m.weights = numpy.ones(n_samples)/n_samples \n",
    "            except AttributeError:\n",
    "                raise Exception(\"Risk averse parameters unset!\")\n",
    "            \n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            \"<{} solver instance, {} processes, {} steps>\"\n",
    "            .format(self.__class__, self.n_processes, self.n_steps)\n",
    "        )\n",
    "\n",
    "    def _compute_idx(self, t):\n",
    "        return (t,t)\n",
    "\n",
    "    def _select_trial_solution(self, random_state, forward_solution):\n",
    "        return forward_solution[:-1]\n",
    "    \n",
    "    \n",
    "\n",
    "    def _forward(\n",
    "            self,\n",
    "            random_state=None,\n",
    "            sample_path_idx=None,\n",
    "            markovian_idx=None,\n",
    "            markovian_samples=None,\n",
    "            solve_true=False,\n",
    "            query=None,\n",
    "            query_dual=None,\n",
    "            query_stage_cost=None):\n",
    "        \"\"\"Single forward step. \"\"\"\n",
    "        MSP = self.MSP\n",
    "        forward_solution = [None for _ in range(self.forward_T)]\n",
    "        pv = 0\n",
    "        query = [] if query is None else list(query)\n",
    "        query_dual = [] if query_dual is None else list(query_dual)\n",
    "        solution = {item: numpy.full(self.forward_T,numpy.nan) for item in query}\n",
    "        solution_dual = {item: numpy.full(self.forward_T,numpy.nan) for item in query_dual}\n",
    "        stage_cost = numpy.full(self.forward_T,numpy.nan)\n",
    "        # time loop\n",
    "        for t in range(self.forward_T):\n",
    "            idx, tm_idx = self._compute_idx(t)\n",
    "            if MSP._type == \"stage-wise independent\":\n",
    "                m = MSP.models[idx]\n",
    "            else:\n",
    "                if t == 0:\n",
    "                    m = MSP.models[idx][0]\n",
    "                    state = 0\n",
    "                else:\n",
    "                    if sample_path_idx is not None:\n",
    "                        state = sample_path_idx[1][t]\n",
    "                    elif markovian_idx is not None:\n",
    "                        state = markovian_idx[t]\n",
    "                    else:\n",
    "                        state = random_state.choice(\n",
    "                            range(MSP.n_Markov_states[idx]),\n",
    "                            p=MSP.transition_matrix[tm_idx][state]\n",
    "                        )\n",
    "                    m = MSP.models[idx][state]\n",
    "                    if markovian_idx is not None:\n",
    "                        m._update_uncertainty_dependent(markovian_samples[t])\n",
    "            if t > 0:\n",
    "                m._update_link_constrs(forward_solution[t-1])\n",
    "                # exhaustive evaluation when the sample paths are given\n",
    "                if sample_path_idx is not None:\n",
    "                    if MSP._type == \"stage-wise independent\":\n",
    "                        scen = sample_path_idx[t]\n",
    "                    else:\n",
    "                        scen = sample_path_idx[0][t]\n",
    "                    m._update_uncertainty(scen)\n",
    "                # true stagewise independent randomness is infinite and solve\n",
    "                # for true\n",
    "                elif m._type == 'continuous' and solve_true:\n",
    "                    m._sample_uncertainty(random_state)\n",
    "                # true stagewise independent randomness is large and solve\n",
    "                # for true\n",
    "                elif m._type == 'discrete' and m._flag_discrete == 1 and solve_true:\n",
    "                    scen = rand_int(\n",
    "                        k=m.n_samples_discrete,\n",
    "                        probability=m.probability,\n",
    "                        random_state=random_state,\n",
    "                    )\n",
    "                    m._update_uncertainty(scen)\n",
    "                # other cases include\n",
    "                # 1: true stagewise independent randomness is infinite and solve\n",
    "                # for approximation problem\n",
    "                # 2: true stagewise independent randomness is large and solve\n",
    "                # for approximation problem\n",
    "                # 3: true stagewise independent randomness is small. In this\n",
    "                # case, true problem and approximation problem are the same.\n",
    "                else:\n",
    "                    if self.biased_sampling:\n",
    "                        sampling_probability = m.weights\n",
    "                    else:\n",
    "                        sampling_probability = m.probability\n",
    "\n",
    "                    scen = rand_int(\n",
    "                        k=m.n_samples,\n",
    "                        probability=sampling_probability,\n",
    "                        random_state=random_state,\n",
    "                    )\n",
    "                    m._update_uncertainty(scen)\n",
    "            if self.iteration != 0 and self.rgl_a != 0:\n",
    "                m.regularize(self.rgl_center[t], self.rgl_norm, self.rgl_a,\n",
    "                self.rgl_b, self.iteration)\n",
    "            m.optimize()\n",
    "            if m.status not in [2,11]:\n",
    "                m.write_infeasible_model(\"forward_\" + str(m.modelName))\n",
    "            forward_solution[t] = MSP._get_forward_solution(m, t)\n",
    "            for var in m.getVars():\n",
    "                if var.varName in query:\n",
    "                    solution[var.varName][t] = var.X\n",
    "            for constr in m.getConstrs():\n",
    "                if constr.constrName in query_dual:\n",
    "                    solution_dual[constr.constrName][t] = constr.PI\n",
    "            if query_stage_cost:\n",
    "                stage_cost[t] = MSP._get_stage_cost(m, t)/pow(MSP.discount, t)\n",
    "            pv += MSP._get_stage_cost(m, t)\n",
    "            if markovian_idx is not None:\n",
    "                m._update_uncertainty_dependent(MSP.Markov_states[idx][markovian_idx[t]])\n",
    "            if self.iteration != 0 and self.rgl_a != 0:\n",
    "                m._deregularize()\n",
    "        #! time loop\n",
    "        if query == [] and query_dual == [] and query_stage_cost is None:\n",
    "            return {\n",
    "                'forward_solution':forward_solution,\n",
    "                'pv':pv\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'solution':solution,\n",
    "                'soultion_dual':solution_dual,\n",
    "                'stage_cost':stage_cost,\n",
    "                'forward_solution':forward_solution,\n",
    "                'pv':pv\n",
    "            }\n",
    "\n",
    "    def _add_and_store_cuts(\n",
    "        self, t, rhs, grad, cuts=None, cut_type=None, j=None\n",
    "    ):\n",
    "        \"\"\"Store cut information (rhs and grad) to cuts for the j th step, for cut\n",
    "        type cut_type and for stage t.\"\"\"\n",
    "        MSP = self.MSP\n",
    "        if MSP.n_Markov_states == 1:\n",
    "            MSP.models[t-1]._add_cut(rhs, grad)\n",
    "            if cuts is not None:\n",
    "                cuts[t-1][cut_type][j][:] = numpy.append(rhs, grad)\n",
    "        else:\n",
    "            for k in range(MSP.n_Markov_states[t-1]):\n",
    "                MSP.models[t-1][k]._add_cut(rhs[k], grad[k])\n",
    "                if cuts is not None:\n",
    "                    cuts[t-1][cut_type][j][k][:] = numpy.append(rhs[k], grad[k])\n",
    "\n",
    "    def _compute_cuts(self, t, m, objLPScen, gradLPScen):\n",
    "        MSP = self.MSP\n",
    "        if MSP.n_Markov_states == 1:\n",
    "            return m._average(objLPScen[0], gradLPScen[0])\n",
    "        objLPScen = objLPScen.reshape(\n",
    "            MSP.n_Markov_states[t]*MSP.n_samples[t])\n",
    "        gradLPScen = gradLPScen.reshape(\n",
    "            MSP.n_Markov_states[t]*MSP.n_samples[t],MSP.n_states[t])\n",
    "        probability_ind = (\n",
    "            m.probability if m.probability\n",
    "            else numpy.ones(m.n_samples)/m.n_samples\n",
    "        )\n",
    "        probability = numpy.einsum('ij,k->ijk',MSP.transition_matrix[t],\n",
    "            probability_ind)\n",
    "        probability = probability.reshape(MSP.n_Markov_states[t-1],\n",
    "            MSP.n_Markov_states[t]*MSP.n_samples[t])\n",
    "        objLP = numpy.empty(MSP.n_Markov_states[t-1])\n",
    "        gradLP = numpy.empty((MSP.n_Markov_states[t-1],MSP.n_states[t]))\n",
    "        for k in range(MSP.n_Markov_states[t-1]):\n",
    "            objLP[k], gradLP[k] = m._average(objLPScen, gradLPScen,\n",
    "                probability[k])\n",
    "        return objLP, gradLP\n",
    "\n",
    "    def _backward(self, forward_solution, j=None, lock=None, cuts=None):\n",
    "        \"\"\"Single backward step of SDDP serially or in parallel.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        forward_solution:\n",
    "            feasible solutions obtained from forward step\n",
    "\n",
    "        j: int\n",
    "            index of forward sampling\n",
    "\n",
    "        lock: multiprocessing.Lock\n",
    "\n",
    "        cuts: dict\n",
    "            A dictionary stores cuts coefficients and rhs.\n",
    "            Key of the dictionary is the cut type. Value of the dictionary is\n",
    "            the cut coefficients and rhs.\n",
    "        \"\"\"\n",
    "        MSP = self.MSP\n",
    "        for t in range(MSP.T-1, 0, -1):\n",
    "            if MSP.n_Markov_states == 1:\n",
    "                M, n_Markov_states = [MSP.models[t]], 1\n",
    "            else:\n",
    "                M, n_Markov_states = MSP.models[t], MSP.n_Markov_states[t]\n",
    "            objLPScen = numpy.empty((n_Markov_states, MSP.n_samples[t]))\n",
    "            gradLPScen = numpy.empty((n_Markov_states, MSP.n_samples[t],\n",
    "                MSP.n_states[t]))\n",
    "            for k,m in enumerate(M):\n",
    "                if MSP.n_Markov_states != 1:\n",
    "                    m._update_link_constrs(forward_solution[t-1])\n",
    "                objLPScen[k], gradLPScen[k] = m._solveLP()\n",
    "\n",
    "                if self.biased_sampling:\n",
    "                    self._compute_bs_frequency(objLPScen[k], m, t)\n",
    "\n",
    "            objLP, gradLP = self._compute_cuts(t, m, objLPScen, gradLPScen)\n",
    "            objLP -= numpy.matmul(gradLP, forward_solution[t-1])\n",
    "            self._add_and_store_cuts(t, objLP, gradLP, cuts, \"B\", j)\n",
    "            self._add_cuts_additional_procedure(t, objLP, gradLP, objLPScen,\n",
    "            gradLPScen, forward_solution[t-1], cuts, \"B\", j)\n",
    "\n",
    "    def _add_cuts_additional_procedure(*args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def _compute_bs_frequency(self,obj, m, t):\n",
    "        \n",
    "        n_samples = m.n_samples\n",
    "        \n",
    "        if self.iteration > 0:\n",
    "            objSortedIndex = numpy.argsort(obj)\n",
    "            tempSum = 0\n",
    "\n",
    "            for index in objSortedIndex:\n",
    "                tempSum += m.weights[index]\n",
    "                if tempSum >= 1 - self.a[t]:\n",
    "                    obj_kappa = index\n",
    "                    break\n",
    "\n",
    "            for k in range(n_samples):\n",
    "                if obj[k] >= obj[obj_kappa]:\n",
    "                    m.counts[k] += 1\n",
    "                m.counts[k] *= 1 - math.pow(0.5, self.iteration)\n",
    "\n",
    "            countSorted = numpy.sort(m.counts)\n",
    "            countSortedIndex = numpy.argsort(m.counts)\n",
    "              \n",
    "            kappa = math.ceil((1-self.a[t])*n_samples)\n",
    "            count_kappa = countSorted[kappa-1]\n",
    "              \n",
    "            upper_orders = countSortedIndex[[i for i in range(n_samples) \n",
    "                                           if i > kappa-1]]\n",
    "            lower_orders = countSortedIndex[[i for i in range(n_samples) \n",
    "                                           if i < kappa-1]]                               \n",
    "\n",
    "            for k in range(n_samples):\n",
    "                if m.counts[k] < count_kappa:\n",
    "                    m.weights[k] = (1-self.l[t])/n_samples\n",
    "                elif m.counts[k] == count_kappa and k in lower_orders:\n",
    "                    m.weights[k] = (1-self.l[t])/n_samples\n",
    "                elif m.counts[k] == count_kappa and k not in upper_orders:\n",
    "                    m.weights[k] = ((1-self.l[t])/n_samples + self.l[t] \n",
    "                         - self.l[t]*(n_samples-kappa)/(self.a[t] * n_samples))\n",
    "                elif m.counts[k] > count_kappa or k in upper_orders:\n",
    "                    m.weights[k] = ((1-self.l[t])/n_samples \n",
    "                                 + self.l[t]/(self.a[t] * n_samples))\n",
    "        \n",
    "\n",
    "    def _SDDP_single(self):\n",
    "        \"\"\"A single serial SDDP step. Returns the policy value.\"\"\"\n",
    "        # random_state is constructed by number of iteration.\n",
    "        random_state = numpy.random.RandomState(self.iteration)\n",
    "        temp = self._forward(random_state)\n",
    "        solution = temp['forward_solution']\n",
    "        pv = temp['pv']\n",
    "        self.rgl_center = solution\n",
    "        solution = self._select_trial_solution(random_state, solution)\n",
    "        self._backward(solution)\n",
    "        return [pv]\n",
    "\n",
    "    def _SDDP_single_process(self, pv, jobs, lock, cuts, forward_solution=None):\n",
    "        \"\"\"Multiple SDDP jobs by single process. pv will store the policy values.\n",
    "        cuts will store the cut information. Have not use the lock parameter so\n",
    "        far.\"\"\"\n",
    "        # random_state is constructed by the number of iteration and the index\n",
    "        # of the first job that the current process does\n",
    "        random_state = numpy.random.RandomState([self.iteration, jobs[0]])\n",
    "        for j in jobs:\n",
    "            temp = self._forward(random_state)\n",
    "            solution = temp['forward_solution']\n",
    "            pv[j] = temp['pv']\n",
    "            # regularization needs to store last forward_solution\n",
    "            if j == jobs[-1] and self.rgl_a != 0:\n",
    "                for t in range(self.forward_T):\n",
    "                    idx,_ = self._compute_idx(t)\n",
    "                    for i in range(self.MSP.n_states[idx]):\n",
    "                        forward_solution[t][i] = solution[t][i]\n",
    "            solution = self._select_trial_solution(random_state, solution)\n",
    "            self._backward(solution, j, lock, cuts)\n",
    "\n",
    "    def _add_cut_from_multiprocessing_array(self, cuts):\n",
    "        for t in range(self.cut_T):\n",
    "            for cut_type in self.cut_type_list[t]:\n",
    "                for cut in cuts[t][cut_type]:\n",
    "                    if self.MSP.n_Markov_states == 1:\n",
    "                        self.MSP.models[t]._add_cut(rhs=cut[0], gradient=cut[1:])\n",
    "                    else:\n",
    "                        for k in range(self.MSP.n_Markov_states[t]):\n",
    "                            self.MSP.models[t][k]._add_cut(\n",
    "                                rhs=cut[k][0], gradient=cut[k][1:])\n",
    "\n",
    "    def _remove_redundant_cut(self, clean_stages):\n",
    "        for t in clean_stages:\n",
    "            M = (\n",
    "                [self.MSP.models[t]]\n",
    "                if self.MSP.n_Markov_states == 1\n",
    "                else self.MSP.models[t]\n",
    "            )\n",
    "            for m in M:\n",
    "                m.update()\n",
    "                constr = m.cuts\n",
    "                for idx, cut in enumerate(constr):\n",
    "                    if cut.sense == '>': cut.sense = '<'\n",
    "                    elif cut.sense == '<': cut.sense = '>'\n",
    "                    flag = 1\n",
    "                    for k in range(m.n_samples):\n",
    "                        m._update_uncertainty(k)\n",
    "                        m.optimize()\n",
    "                        if m.status == 4:\n",
    "                            m.Params.DualReductions = 0\n",
    "                            m.optimize()\n",
    "                        if m.status not in [3,11]:\n",
    "                            flag = 0\n",
    "                    if flag == 1:\n",
    "                        m._remove_cut(idx)\n",
    "                    else:\n",
    "                        if cut.sense == '>': cut.sense = '<'\n",
    "                        elif cut.sense == '<': cut.sense = '>'\n",
    "                m.update()\n",
    "\n",
    "    def _compute_cut_type(self):\n",
    "        pass\n",
    "\n",
    "    def _SDDP_multiprocessesing(self):\n",
    "        \"\"\"Prepare a collection of multiprocessing arrays to store cuts.\n",
    "        Cuts are stored in the form of:\n",
    "         Independent case (index: t, cut_type, j):\n",
    "            {t:{cut_type: [cut_coeffs_and_rhs]}\n",
    "         Markovian case (index: t, cut_type, j, k):\n",
    "            {t:{cut_type: [[cut_coeffs_and_rhs]]}\n",
    "        \"\"\"\n",
    "        procs = [None] * self.n_processes\n",
    "        if self.MSP.n_Markov_states == 1:\n",
    "            cuts = {\n",
    "                t:{\n",
    "                    cut_type: [multiprocessing.RawArray(\"d\",\n",
    "                        [0] * (self.MSP.n_states[t]+1))\n",
    "                        for _ in range(self.n_steps)]\n",
    "                    for cut_type in self.cut_type_list[t]}\n",
    "            for t in range(self.cut_T)}\n",
    "        else:\n",
    "            cuts = {\n",
    "                t:{\n",
    "                    cut_type: [\n",
    "                        [multiprocessing.RawArray(\"d\",\n",
    "                            [0] * (self.MSP.n_states[t]+1))\n",
    "                            for _ in range(self.MSP.n_Markov_states[t])]\n",
    "                        for _ in range(self.n_steps)]\n",
    "                    for cut_type in self.cut_type_list[t]}\n",
    "            for t in range(self.cut_T)}\n",
    "\n",
    "        pv = multiprocessing.Array(\"d\", [0] * self.n_steps)\n",
    "        lock = multiprocessing.Lock()\n",
    "        forward_solution = None\n",
    "        # regularization needs to store last forward_solution\n",
    "        if self.rgl_a != 0:\n",
    "            forward_solution = [multiprocessing.Array(\n",
    "                \"d\",[0] * self.MSP.n_states[self._compute_idx(t)[0]])\n",
    "                for t in range(self.forward_T)\n",
    "            ]\n",
    "\n",
    "        for p in range(self.n_processes):\n",
    "            procs[p] = multiprocessing.Process(\n",
    "                target=self._SDDP_single_process,\n",
    "                args=(pv, self.jobs[p], lock, cuts, forward_solution),\n",
    "            )\n",
    "            procs[p].start()\n",
    "        for proc in procs:\n",
    "            proc.join()\n",
    "\n",
    "        self._add_cut_from_multiprocessing_array(cuts)\n",
    "        # regularization needs to store last forward_solution\n",
    "        if self.rgl_a != 0:\n",
    "            self.rgl_center = [list(item) for item in forward_solution]\n",
    "\n",
    "        return [item for item in pv]\n",
    "\n",
    "    def solve(\n",
    "            self,\n",
    "            n_processes=1,\n",
    "            n_steps=1,\n",
    "            max_iterations=10000,\n",
    "            max_stable_iterations=10000,\n",
    "            max_time=1000000.0,\n",
    "            tol=0.001,\n",
    "            freq_evaluations=None,\n",
    "            percentile=95,\n",
    "            tol_diff=float(\"-inf\"),\n",
    "            random_state=None,\n",
    "            evaluation_true=False,\n",
    "            freq_comparisons=None,\n",
    "            n_simulations=3000,\n",
    "            n_simulations_true=3000,\n",
    "            query=None,\n",
    "            query_T=None,\n",
    "            query_dual=None,\n",
    "            query_stage_cost=False,\n",
    "            query_policy_value=False,\n",
    "            freq_clean=None,\n",
    "            logFile=1,\n",
    "            logToConsole=1,\n",
    "            directory='',\n",
    "            rgl_norm='L2',\n",
    "            rgl_a=0,\n",
    "            rgl_b=0.95,\n",
    "            ):\n",
    "        \"\"\"Solve the discretized problem.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        n_processes: int, optional (default=1)\n",
    "            The number of processes to run in parallel. Run serial SDDP if 1.\n",
    "            If n_steps is 1, n_processes is coerced to be 1.\n",
    "\n",
    "        n_steps: int, optional (default=1)\n",
    "            The number of forward/backward steps to run in each cut iteration.\n",
    "            It is coerced to be 1 if n_processes is 1.\n",
    "\n",
    "        max_iterations: int, optional (default=10000)\n",
    "            The maximum number of iterations to run SDDP.\n",
    "\n",
    "        max_stable_iterations: int, optional (default=10000)\n",
    "            The maximum number of iterations to have same deterministic bound\n",
    "\n",
    "        tol: float, optional (default=1e-3)\n",
    "            tolerance for convergence of bounds\n",
    "\n",
    "        freq_evaluations: int, optional (default=None)\n",
    "            The frequency of evaluating gap on the discretized problem. It will\n",
    "            be ignored if risk averse\n",
    "\n",
    "        percentile: float, optional (default=95)\n",
    "            The percentile used to compute confidence interval\n",
    "\n",
    "        diff: float, optional (default=-inf)\n",
    "            The stabilization threshold\n",
    "\n",
    "        freq_comparisons: int, optional (default=None)\n",
    "            The frequency of comparisons of policies\n",
    "\n",
    "        n_simulations: int, optional (default=10000)\n",
    "            The number of simluations to run when evaluating a policy\n",
    "            on the discretized problem\n",
    "\n",
    "        freq_clean: int/list, optional (default=None)\n",
    "            The frequency of removing redundant cuts.\n",
    "            If int, perform cleaning at the same frequency for all stages.\n",
    "            If list, perform cleaning at different frequency for each stage;\n",
    "            must be of length T-1 (the last stage does not have any cuts).\n",
    "\n",
    "        random_state: int, RandomState instance or None, optional (default=None)\n",
    "            Used in evaluations and comparisons. (In the forward step, there is\n",
    "            an internal random_state which is not supposed to be changed.)\n",
    "            If int, random_state is the seed used by the random number\n",
    "            generator;\n",
    "            If RandomState instance, random_state is the random number\n",
    "            generator;\n",
    "            If None, the random number generator is the RandomState\n",
    "            instance used by numpy.random.\n",
    "\n",
    "        logFile: binary, optional (default=1)\n",
    "            Switch of logging to log file\n",
    "\n",
    "        logToConsole: binary, optional (default=1)\n",
    "            Switch of logging to console\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "\n",
    "        >>> SDDP().solve(max_iterations=10, max_time=10,\n",
    "            max_stable_iterations=10)\n",
    "        Optimality gap based stopping criteria: evaluate the obtained policy\n",
    "        every freq_evaluations iterations by running n_simulations Monte Carlo\n",
    "        simulations. If the gap becomes not larger than tol, the algorithm\n",
    "        will be stopped.\n",
    "        >>> SDDP().solve(freq_evaluations=10, n_simulations=1000, tol=1e-2)\n",
    "        Simulation can be turned off; the solver will evaluate the exact expected\n",
    "        policy value.\n",
    "        >>> SDDP().solve(freq_evaluation=10, n_simulations=-1, tol=1e-2)\n",
    "        Stabilization based stopping criteria: compare the policy every\n",
    "        freq_comparisons iterations by computing the CI of difference of the\n",
    "        expected policy values. If the upper end of CI becomes not larger\n",
    "        than tol diff, the algorithm will be stopped.\n",
    "        >>> SDDP().solve(freq_comparisons=10, n_simulations=1000, tol=1e-2)\n",
    "        Turn off simulation and\n",
    "\n",
    "        \"\"\"\n",
    "        MSP = self.MSP\n",
    "        if freq_clean is not None:\n",
    "            if isinstance(freq_clean, (numbers.Integral, numpy.integer)):\n",
    "                freq_clean = [freq_clean] * (MSP.T-1)\n",
    "            if isinstance(freq_clean, ((abc.Sequence, numpy.ndarray))):\n",
    "                if len(freq_clean) != MSP.T-1:\n",
    "                    raise ValueError(\"freq_clean list must be of length T-1!\")\n",
    "            else:\n",
    "                raise TypeError(\"freq_clean must be int/list instead of {}!\"\n",
    "                .format(type(freq_clean)))\n",
    "        if not MSP._flag_update:\n",
    "            MSP._update()\n",
    "        stable_iterations = 0\n",
    "        total_time = 0\n",
    "        a = time.time()\n",
    "        gap = 1.0\n",
    "        right_end_of_CI = float(\"inf\")\n",
    "        db_past = MSP.bound\n",
    "        self.percentile = percentile\n",
    "        self.rgl_norm = rgl_norm\n",
    "        self.rgl_a = rgl_a\n",
    "        self.rgl_b = rgl_b\n",
    "\n",
    "\n",
    "        # distinguish pv_sim from pv\n",
    "        pv_sim_past = None\n",
    "\n",
    "        if n_processes != 1:\n",
    "            self.n_steps = n_steps\n",
    "            self.n_processes = min(n_steps, n_processes)\n",
    "            self.jobs = allocate_jobs(self.n_steps, self.n_processes)\n",
    "\n",
    "        logger_sddp = LoggerSDDP(\n",
    "            logFile=logFile,\n",
    "            logToConsole=logToConsole,\n",
    "            n_processes=self.n_processes,\n",
    "            percentile=self.percentile,\n",
    "            directory=directory,\n",
    "        )\n",
    "        logger_sddp.header()\n",
    "        if freq_evaluations is not None or freq_comparisons is not None:\n",
    "            logger_evaluation = LoggerEvaluation(\n",
    "                n_simulations=n_simulations,\n",
    "                percentile=percentile,\n",
    "                logFile=logFile,\n",
    "                logToConsole=logToConsole,\n",
    "                directory=directory,\n",
    "            )\n",
    "            logger_evaluation.header()\n",
    "        if freq_comparisons is not None:\n",
    "            logger_comparison = LoggerComparison(\n",
    "                n_simulations=n_simulations,\n",
    "                percentile=percentile,\n",
    "                logFile=logFile,\n",
    "                logToConsole=logToConsole,\n",
    "                directory=directory,\n",
    "            )\n",
    "            logger_comparison.header()\n",
    "        try:\n",
    "            while (\n",
    "                self.iteration < max_iterations\n",
    "                and total_time < max_time\n",
    "                and stable_iterations < max_stable_iterations\n",
    "                and tol < gap\n",
    "                and (tol_diff < right_end_of_CI or right_end_of_CI < 0)\n",
    "            ):\n",
    "                start = time.time()\n",
    "\n",
    "                self._compute_cut_type()\n",
    "\n",
    "                if self.n_processes == 1:\n",
    "                    pv = self._SDDP_single()\n",
    "                else:\n",
    "                    pv = self._SDDP_multiprocessesing()\n",
    "\n",
    "                m = (\n",
    "                    MSP.models[0]\n",
    "                    if MSP.n_Markov_states == 1\n",
    "                    else MSP.models[0][0]\n",
    "                )\n",
    "                m.optimize()\n",
    "                if m.status not in [2,11]:\n",
    "                    m.write_infeasible_model(\n",
    "                        \"backward_\" + str(m._model.modelName) + \".lp\"\n",
    "                    )\n",
    "                db = m.objBound\n",
    "                self.db.append(db)\n",
    "                MSP.db = db\n",
    "                if self.n_processes != 1:\n",
    "                    CI = compute_CI(pv,percentile)\n",
    "                self.pv.append(pv)\n",
    "\n",
    "                if self.iteration >= 1:\n",
    "                    if db_past == db:\n",
    "                        stable_iterations += 1\n",
    "                    else:\n",
    "                        stable_iterations = 0\n",
    "                self.iteration += 1\n",
    "                db_past = db\n",
    "\n",
    "                end = time.time()\n",
    "                elapsed_time = end - start\n",
    "                total_time += elapsed_time\n",
    "\n",
    "                if self.n_processes == 1:\n",
    "                    logger_sddp.text(\n",
    "                        iteration=self.iteration,\n",
    "                        db=db,\n",
    "                        pv=pv[0],\n",
    "                        time=elapsed_time,\n",
    "                    )\n",
    "                else:\n",
    "                    logger_sddp.text(\n",
    "                        iteration=self.iteration,\n",
    "                        db=db,\n",
    "                        CI=CI,\n",
    "                        time=elapsed_time,\n",
    "                    )\n",
    "                if (\n",
    "                    freq_evaluations is not None\n",
    "                    and self.iteration%freq_evaluations == 0\n",
    "                    or freq_comparisons is not None\n",
    "                    and self.iteration%freq_comparisons == 0\n",
    "                ):\n",
    "                    directory = '' if directory is None else directory\n",
    "                    start = time.time()\n",
    "                    evaluation = Evaluation(MSP)\n",
    "                    evaluation.run(\n",
    "                        n_simulations=n_simulations,\n",
    "                        query=query,\n",
    "                        query_T=query_T,\n",
    "                        query_dual=query_dual,\n",
    "                        query_stage_cost=query_stage_cost,\n",
    "                        percentile=percentile,\n",
    "                        n_processes=n_processes,\n",
    "                    )\n",
    "                    if query_policy_value:\n",
    "                        pandas.DataFrame(evaluation.pv).to_csv(directory+\n",
    "                            \"iter_{}_pv.csv\".format(self.iteration))\n",
    "                    if query is not None:\n",
    "                        for item in query:\n",
    "                            evaluation.solution[item].to_csv(directory+\n",
    "                                \"iter_{}_{}.csv\".format(self.iteration, item))\n",
    "                    if query_dual is not None:\n",
    "                        for item in query_dual:\n",
    "                            evaluation.solution_dual[item].to_csv(directory+\n",
    "                                \"iter_{}_{}.csv\".format(self.iteration, item))\n",
    "                    if query_stage_cost:\n",
    "                        evaluation.stage_cost.to_csv(directory+\n",
    "                            \"iter_{}_stage_cost.csv\".format(self.iteration))\n",
    "                    if evaluation_true:\n",
    "                        evaluationTrue = EvaluationTrue(MSP)\n",
    "                        evaluationTrue.run(\n",
    "                            n_simulations=n_simulations,\n",
    "                            query=query,\n",
    "                            query_T=query_T,\n",
    "                            query_dual=query_dual,\n",
    "                            query_stage_cost=query_stage_cost,\n",
    "                            percentile=percentile,\n",
    "                            n_processes=n_processes,\n",
    "                        )\n",
    "                        if query_policy_value:\n",
    "                            pandas.DataFrame(evaluationTrue.pv).to_csv(directory+\n",
    "                                \"iter_{}_pv_true.csv\".format(self.iteration))\n",
    "                        if query is not None:\n",
    "                            for item in query:\n",
    "                                evaluationTrue.solution[item].to_csv(directory+\n",
    "                                    \"iter_{}_{}_true.csv\".format(self.iteration, item))\n",
    "                        if query_dual is not None:\n",
    "                            for item in query_dual:\n",
    "                                evaluationTrue.solution_dual[item].to_csv(directory+\n",
    "                                    \"iter_{}_{}_true.csv\".format(self.iteration, item))\n",
    "                        if query_stage_cost:\n",
    "                            evaluationTrue.stage_cost.to_csv(directory+\n",
    "                                \"iter_{}_stage_cost_true.csv\".format(self.iteration))\n",
    "                    elapsed_time = time.time() - start\n",
    "                    gap = evaluation.gap\n",
    "                    if n_simulations == -1:\n",
    "                        logger_evaluation.text(\n",
    "                            iteration=self.iteration,\n",
    "                            db=db,\n",
    "                            pv=evaluation.epv,\n",
    "                            gap=gap,\n",
    "                            time=elapsed_time,\n",
    "                        )\n",
    "                    elif n_simulations == 1:\n",
    "                        logger_evaluation.text(\n",
    "                            iteration=self.iteration,\n",
    "                            db=db,\n",
    "                            pv=evaluation.pv,\n",
    "                            gap=gap,\n",
    "                            time=elapsed_time,\n",
    "                        )\n",
    "                    else:\n",
    "                        logger_evaluation.text(\n",
    "                            iteration=self.iteration,\n",
    "                            db=db,\n",
    "                            CI=evaluation.CI,\n",
    "                            gap=gap,\n",
    "                            time=elapsed_time,\n",
    "                        )\n",
    "                if (\n",
    "                    freq_comparisons is not None\n",
    "                    and self.iteration%freq_comparisons == 0\n",
    "                ):\n",
    "                    start = time.time()\n",
    "                    pv_sim = evaluation.pv\n",
    "                    if self.iteration / freq_comparisons >= 2:\n",
    "                        diff = MSP.sense*(numpy.array(pv_sim_past)-numpy.array(pv_sim))\n",
    "                        if n_simulations == -1:\n",
    "                            diff_mean = numpy.mean(diff)\n",
    "                            right_end_of_CI = diff_mean\n",
    "                        else:\n",
    "                            diff_CI = compute_CI(diff, self.percentile)\n",
    "                            right_end_of_CI = diff_CI[1]\n",
    "                        elapsed_time = time.time() - start\n",
    "                        if n_simulations == -1:\n",
    "                            logger_comparison.text(\n",
    "                                iteration=self.iteration,\n",
    "                                ref_iteration=self.iteration-freq_comparisons,\n",
    "                                diff=diff_mean,\n",
    "                                time=elapsed_time,\n",
    "                            )\n",
    "                        else:\n",
    "                            logger_comparison.text(\n",
    "                                iteration=self.iteration,\n",
    "                                ref_iteration=self.iteration-freq_comparisons,\n",
    "                                diff_CI=diff_CI,\n",
    "                                time=elapsed_time,\n",
    "                            )\n",
    "                    pv_sim_past = pv_sim\n",
    "                if freq_clean is not None:\n",
    "                    clean_stages = [\n",
    "                        t\n",
    "                        for t in range(1,MSP.T-1)\n",
    "                        if self.iteration%freq_clean[t] == 0\n",
    "                    ]\n",
    "                    if len(clean_stages) != 0:\n",
    "                        self._remove_redundant_cut(clean_stages)\n",
    "                # self._clean()\n",
    "        except KeyboardInterrupt:\n",
    "            stop_reason = \"interruption by the user\"\n",
    "        # SDDP iteration stops\n",
    "        MSP.db = self.db[-1]\n",
    "        if self.iteration >= max_iterations:\n",
    "            stop_reason = \"iteration:{} has reached\".format(max_iterations)\n",
    "        if total_time >= max_time:\n",
    "            stop_reason = \"time:{} has reached\".format(max_time)\n",
    "        if stable_iterations >= max_stable_iterations:\n",
    "            stop_reason = \"stable iteration:{} has reached\".format(max_stable_iterations)\n",
    "        if gap <= tol:\n",
    "            stop_reason = \"convergence tolerance:{} has reached\".format(tol)\n",
    "        if right_end_of_CI <= tol_diff:\n",
    "            stop_reason = \"stabilization threshold:{} has reached\".format(tol_diff)\n",
    "\n",
    "        b = time.time()\n",
    "        logger_sddp.footer(reason=stop_reason)\n",
    "        if freq_evaluations is not None or freq_comparisons is not None:\n",
    "            logger_evaluation.footer()\n",
    "        if freq_comparisons is not None:\n",
    "            logger_comparison.footer()\n",
    "        self.total_time = total_time\n",
    "\n",
    "    @property\n",
    "    def first_stage_solution(self):\n",
    "        \"\"\"the obtained solution in the first stage\"\"\"\n",
    "        return (\n",
    "            {var.varName: var.X for var in self.MSP.models[0].getVars()}\n",
    "            if self.MSP.n_Markov_states == 1\n",
    "            else {var.varName: var.X for var in self.MSP.models[0][0].getVars()}\n",
    "        )\n",
    "\n",
    "    def plot_bounds(self, start=0, window=1, smooth=0, ax=None):\n",
    "        \"\"\"\n",
    "        plot the evolution of bounds\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ax: Matplotlib AxesSubplot instance, optional\n",
    "            The specified subplot is used to plot; otherwise a new figure is created.\n",
    "\n",
    "        window: int, optional (default=1)\n",
    "            The length of the moving windows to aggregate the policy values. If\n",
    "            length is bigger than 1, approximate confidence interval of the\n",
    "            policy values and statistical bounds will be plotted.\n",
    "\n",
    "        smooth: bool, optional (default=0)\n",
    "            If 1, fit a smooth line to the policy values to better visualize\n",
    "            the trend of statistical values/bounds.\n",
    "\n",
    "        start: int, optional (default=0)\n",
    "            The start iteration to plot the bounds. Set start to other values\n",
    "            can zoom in the evolution of bounds in most recent iterations.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        matplotlib.pyplot.figure instance\n",
    "        \"\"\"\n",
    "        from msppy.utils.plot import plot_bounds\n",
    "        return plot_bounds(self.db, self.pv, self.MSP.sense, self.percentile,\n",
    "        start=start, window=window, smooth=smooth, ax=ax)\n",
    "\n",
    "    @property\n",
    "    def bounds(self):\n",
    "        \"\"\"dataframe of the obtained bound\"\"\"\n",
    "        df = pandas.DataFrame.from_records(self.pv)\n",
    "        df['db'] = self.db\n",
    "        return df\n",
    "\n",
    "class SDDiP(SDDP):\n",
    "    __doc__ = SDDP.__doc__\n",
    "\n",
    "    def solve(\n",
    "            self,\n",
    "            cuts,\n",
    "            pattern=None,\n",
    "            relax_stage=None,\n",
    "            level_step_size=0.2929,\n",
    "            level_max_stable_iterations=1000,\n",
    "            level_max_iterations=1000,\n",
    "            level_max_time=1000,\n",
    "            level_mip_gap=1e-4,\n",
    "            level_tol=1e-3,\n",
    "            *args,\n",
    "            **kwargs):\n",
    "        \"\"\"Call SDDiP solver to solve the discretized problem.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cuts: list\n",
    "            Entries of the list could be 'B','SB','LG'\n",
    "\n",
    "        pattern: dict, optional (default=None)\n",
    "            The pattern of adding cuts can be cyclical or barrier-in.\n",
    "            See the example below.\n",
    "\n",
    "        relax_stage: int, optional (default=None)\n",
    "            All stage models after relax_stage (exclusive) will be relaxed.\n",
    "\n",
    "        level_step_size: float, optional (default=0.2929)\n",
    "            Step size for level method.\n",
    "\n",
    "        level_max_stable_iterations: int, optional (default=1000)\n",
    "            The maximum number of iterations to have the same deterministic g_*\n",
    "            for the level method.\n",
    "\n",
    "        level_mip_gap: float, optional (default=1e-4)\n",
    "            The MIPGap used when solving the inner problem for the level method.\n",
    "\n",
    "        level_max_iterations: int, optional (default=1000)\n",
    "            The maximum number of iterations to run for the level method.\n",
    "\n",
    "        level_max_time: int, optional (default=1000)\n",
    "            The maximum number of time to run for the level method.\n",
    "\n",
    "        level_tol: float, optional (default=1e-3)\n",
    "            Tolerance for convergence of bounds for the level method.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        >>> SDDiP().solve(max_iterations=10, cut=['SB'])\n",
    "\n",
    "        The following cyclical add difference cuts. Specifically, for every six\n",
    "        iterations add Benders' cuts for the first four,\n",
    "        strengthened Benders' cuts for the fifth,\n",
    "        and Lagrangian cuts for the last.\n",
    "\n",
    "        >>> SDDiP().solve(max_iterations=10, cut=['B','SB','LG'],\n",
    "        ...     pattern={\"cycle\": (4, 1, 1)})\n",
    "\n",
    "        The following add difference cuts from certain iterations. Specifically,\n",
    "        add Benders' cuts from the beginning,\n",
    "        Strengthened Benders' cuts from the fourth iteration,\n",
    "        and Lagragian cuts from the fifth iteration.\n",
    "\n",
    "        >>> SDDiP().solve(max_iterations=10, cut=['B','SB','LG'],\n",
    "        ...     pattern={'in': (0, 4, 5)})\n",
    "        \"\"\"\n",
    "        if pattern != None:\n",
    "            if not all(\n",
    "                len(item) == len(cuts)\n",
    "                for item in pattern.values()\n",
    "            ):\n",
    "                raise Exception(\"pattern is not compatible with cuts!\")\n",
    "        self.relax_stage = relax_stage if relax_stage != None else self.MSP.T - 1\n",
    "        self.cut_type = cuts\n",
    "        self.cut_pattern = pattern\n",
    "        self.level_step_size = level_step_size\n",
    "        self.level_max_stable_iterations = level_max_stable_iterations\n",
    "        self.level_max_iterations = level_max_iterations\n",
    "        self.level_max_time = level_max_time\n",
    "        self.level_mip_gap = level_mip_gap\n",
    "        self.level_tol = level_tol\n",
    "        super().solve(*args, **kwargs)\n",
    "\n",
    "    def _backward(self, forward_solution, j=None, lock=None, cuts=None):\n",
    "        MSP = self.MSP\n",
    "        for t in range(MSP.T-1, 0, -1):\n",
    "            if MSP.n_Markov_states == 1:\n",
    "                M, n_Markov_states = [MSP.models[t]], 1\n",
    "            else:\n",
    "                M, n_Markov_states = MSP.models[t], MSP.n_Markov_states[t]\n",
    "            objLPScen = numpy.empty((n_Markov_states, MSP.n_samples[t]))\n",
    "            gradLPScen = numpy.empty((n_Markov_states, MSP.n_samples[t],\n",
    "                MSP.n_states[t]))\n",
    "            objSBScen = numpy.empty((n_Markov_states, MSP.n_samples[t]))\n",
    "            objLGScen = numpy.empty((n_Markov_states, MSP.n_samples[t]))\n",
    "            gradLGScen = numpy.empty((n_Markov_states, MSP.n_samples[t],\n",
    "                MSP.n_states[t]))\n",
    "            for k, model in enumerate(M):\n",
    "                if MSP.n_Markov_states != 1:\n",
    "                    model._update_link_constrs(forward_solution[t-1])\n",
    "                model.update()\n",
    "                m = model.relax() if model.isMIP else model\n",
    "                objLPScen[k], gradLPScen[k] = m._solveLP()\n",
    "                # SB and LG share the same model\n",
    "                if (\n",
    "                    \"SB\" in self.cut_type_list[t-1]\n",
    "                    or \"LG\" in self.cut_type_list[t-1]\n",
    "                ):\n",
    "                    m = model.copy()\n",
    "                    m._delete_link_constrs()\n",
    "                if \"SB\" in self.cut_type_list[t-1]:\n",
    "                    objSBScen[k] = m._solveSB(gradLPScen[k])\n",
    "                if \"LG\" in self.cut_type_list[t-1]:\n",
    "                    objVal_primal = model._solvePrimal()\n",
    "                    flag_bin = (\n",
    "                        True if hasattr(self, \"n_binaries\")\n",
    "                        else False\n",
    "                    )\n",
    "                    objLGScen[k], gradLGScen[k] = m._solveLG(\n",
    "                        gradLPScen=gradLPScen[k],\n",
    "                        given_bound=MSP.bound,\n",
    "                        objVal_primal=objVal_primal,\n",
    "                        flag_tight = flag_bin,\n",
    "                        forward_solution=forward_solution[t-1],\n",
    "                        step_size=self.level_step_size,\n",
    "                        max_stable_iterations=self.level_max_stable_iterations,\n",
    "                        max_iterations=self.level_max_iterations,\n",
    "                        max_time=self.level_max_time,\n",
    "                        MIPGap=self.level_mip_gap,\n",
    "                        tol=self.level_tol,\n",
    "                    )\n",
    "            #! Markov states iteration ends\n",
    "            if \"B\" in self.cut_type_list[t-1]:\n",
    "                objLP, gradLP = self._compute_cuts(t, m, objLPScen, gradLPScen)\n",
    "                objLP -= numpy.matmul(gradLP, forward_solution[t-1])\n",
    "                self._add_and_store_cuts(t, objLP, gradLP, cuts, \"B\", j)\n",
    "                self._add_cuts_additional_procedure(t, objLP, gradLP, objLPScen,\n",
    "                    gradLPScen, forward_solution[t-1], cuts, \"B\", j)\n",
    "            if \"SB\" in self.cut_type_list[t-1]:\n",
    "                objSB, gradLP = self._compute_cuts(t, m, objSBScen, gradLPScen)\n",
    "                self._add_and_store_cuts(t, objSB, gradLP, cuts, \"SB\", j)\n",
    "                self._add_cuts_additional_procedure(t, objSB, gradLP, objSBScen,\n",
    "                    gradLPScen, forward_solution[t-1], cuts, \"SB\", j)\n",
    "            if \"LG\" in self.cut_type_list[t-1]:\n",
    "                objLG, gradLG = self._compute_cuts(t, m, objLGScen, gradLGScen)\n",
    "                self._add_and_store_cuts(t, objLG, gradLG, cuts, \"LG\", j)\n",
    "                self._add_cuts_additional_procedure(t, objLG, gradLG, objLGScen,\n",
    "                    gradLGScen, forward_solution[t-1], cuts, \"LG\", j)\n",
    "        #! Time iteration ends\n",
    "\n",
    "    def _compute_cut_type_by_iteration(self):\n",
    "        if self.cut_pattern == None:\n",
    "            return list(self.cut_type)\n",
    "        else:\n",
    "            if \"cycle\" in self.cut_pattern.keys():\n",
    "                cycle = self.cut_pattern[\"cycle\"]\n",
    "                ## decide pos belongs to which interval ##\n",
    "                interval = numpy.cumsum(cycle) - 1\n",
    "                pos = self.iteration % sum(cycle)\n",
    "                for i in range(len(interval)):\n",
    "                    if pos <= interval[i]:\n",
    "                        return [self.cut_type[i]]\n",
    "            if \"in\" in self.cut_pattern.keys():\n",
    "                barrier_in = self.cut_pattern[\"in\"]\n",
    "                cut = []\n",
    "                for i in range(len(barrier_in)):\n",
    "                    if self.iteration >= barrier_in[i]:\n",
    "                        cut.append(self.cut_type[i])\n",
    "                if \"B\" in cut and \"SB\" in cut:\n",
    "                    cut.remove(\"B\")\n",
    "                return cut\n",
    "\n",
    "    def _compute_cut_type_by_stage(self, t, cut_type):\n",
    "        if t > self.relax_stage or self.MSP.isMIP[t] != 1:\n",
    "            cut_type = [\"B\"]\n",
    "        return cut_type\n",
    "\n",
    "    def _compute_cut_type(self):\n",
    "        cut_type_list = [None] * self.cut_T\n",
    "        cut_type_by_iteration = self._compute_cut_type_by_iteration()\n",
    "        for t in range(1, self.cut_T+1):\n",
    "            cut_type_list[t-1] = self._compute_cut_type_by_stage(t, cut_type_by_iteration)\n",
    "        self.cut_type_list = cut_type_list\n",
    "\n",
    "class PSDDP(SDDP):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.forward_T = self.MSP.T\n",
    "        self.cut_T = self.MSP.T\n",
    "        self.period = self.MSP.T-1\n",
    "        self.cut_type_list = [[\"B\"] for t in range(self.cut_T)]\n",
    "\n",
    "    def solve(self, forward_T=None, *args, **kwargs):\n",
    "        # Solve the discretized problem.\n",
    "\n",
    "        if forward_T: self.forward_T = forward_T\n",
    "        self.MSP._set_up_CTG_for_t(-1)\n",
    "        self.MSP._flag_infinity = 1\n",
    "        super().solve(*args, **kwargs)\n",
    "\n",
    "    def _add_cuts_additional_procedure(self, t, rhs, grad, objScen, gradScen, fwdSoln, cuts=None, cut_type=None,j=None):\n",
    "        if t != 1: return\n",
    "        MSP = self.MSP\n",
    "        if MSP.n_Markov_states == 1:\n",
    "            MSP.models[-1]._add_cut(rhs, grad)\n",
    "            if cuts is not None:\n",
    "                cuts[MSP.T-1][cut_type][j] = torch.cat((rhs, grad), dim=0)\n",
    "        else:\n",
    "            objScen = objScen.reshape(MSP.n_Markov_states[1]*MSP.n_samples[1])\n",
    "            gradScen = gradScen.reshape(MSP.n_Markov_states[1]*MSP.n_samples[1],MSP.n_states[1])\n",
    "            probability_ind = numpy.array([m.probability if m.probability else numpy.ones(m.n_samples)/m.n_samples for m in MSP.models[1]])\n",
    "            probability = torch.einsum('ij,jk->ijk',MSP.transition_matrix[-1],probability_ind)\n",
    "            probability = probability.reshape(MSP.n_Markov_states[-1],\n",
    "                MSP.n_Markov_states[1]*MSP.n_samples[1])\n",
    "            for k,m in enumerate(MSP.models[-1]):\n",
    "                rhs_, grad_ = m._average(objScen, gradScen, probability[k])\n",
    "                if cut_type == 'B':\n",
    "                    rhs_ -= torch.matmul(grad_, fwdSoln)\n",
    "                m._add_cut(rhs_, grad_)\n",
    "                if cuts is not None:\n",
    "                    cuts[MSP.T-1][cut_type][j][k] = torch.cat((rhs_, grad_), dim=0)\n",
    "\n",
    "    def _add_cut_from_multiprocessing_array_additional_procedure(self, cuts):\n",
    "        for cut_type in self.cut_type_list[0]:\n",
    "            for cut in cuts[0][cut_type]:\n",
    "                if self.MSP.n_Markov_states == 1:\n",
    "                    self.MSP.models[-1]._add_cut(rhs=cut[0],gradient=cut[1:])\n",
    "                else:\n",
    "                    for k,cut_k in enumerate(cut):\n",
    "                        self.MSP.models[-1][k]._add_cut(rhs=cut_k[0],gradient=cut_k[1:])\n",
    "\n",
    "    def _compute_idx(self, t):\n",
    "        idx = t%self.period if (t%self.period != 0 or t == 0) else self.period\n",
    "        # transition matrix at stage period+1, 2*period+1, ... should be\n",
    "        # additionaly specified.\n",
    "        tm_idx = idx if (t%self.period != 1 or t == 1) else self.period+1\n",
    "        return (idx,tm_idx)\n",
    "\n",
    "    def _select_trial_solution(self, random_state, forward_solution):\n",
    "        # if solving more than one single period, only part of obtained solutions\n",
    "        # would be selected\n",
    "        if self.forward_T > self.period + 1:\n",
    "            indices = numpy.arange(0, self.forward_T, self.period)\n",
    "            idx = indices[rand_int(k=len(indices), random_state=random_state)]\n",
    "            if idx + self.period > self.forward_T:\n",
    "                idx = idx - self.period\n",
    "            for t in range(1, self.period+1):\n",
    "                self.MSP.models[t]._update_link_constrs(forward_solution[idx+t-1])\n",
    "            return forward_solution[idx:idx+self.period]\n",
    "        return forward_solution\n",
    "\n",
    "\n",
    "class Extensive(object):\n",
    "    # Extensive solver class. Can solve\n",
    "    # 1. small-scale stgage-wise independent finite discrete risk netural problem 2.\n",
    "    # small-scale Markov chain risk neutral problem.\n",
    "\n",
    "    def __init__(self, MSP):\n",
    "        self.MSP = MSP\n",
    "        self.solving_time = None\n",
    "        self.construction_time = None\n",
    "        self.total_time = None\n",
    "        self._type = MSP._type\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            return getattr(self.extensive_model, name)\n",
    "        except AttributeError:\n",
    "            raise AttributeError(\"no attribute named {}\".format(name))\n",
    "\n",
    "    def solve(self, start=0, flag_rolling=0, **kwargs):\n",
    "        # Call extensive solver to solve the discretized problem. It will first\n",
    "        # construct the extensive model and then call Gurobi solver to solve it.\n",
    "        # extensive solver is able to solve MSLP with CTG or without CTG\n",
    "        self.MSP._check_individual_stage_models()\n",
    "        self.MSP._check_multistage_model()\n",
    "\n",
    "        construction_start_time = time.time()\n",
    "\n",
    "        self.extensive_model = gurobipy.Model()\n",
    "        self.extensive_model.modelsense = self.MSP.sense\n",
    "        self.start = start\n",
    "\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self.extensive_model.Params, k, v)\n",
    "        self._construct_extensive(flag_rolling)\n",
    "        construction_end_time = time.time()\n",
    "        self.construction_time = construction_end_time - construction_start_time\n",
    "        solving_start_time = time.time()\n",
    "        self.extensive_model.optimize()\n",
    "        solving_end_time = time.time()\n",
    "        self.solving_time = solving_end_time - solving_start_time\n",
    "        self.total_time = self.construction_time + self.solving_time\n",
    "        return self.extensive_model.objVal\n",
    "\n",
    "    def _get_varname(self):\n",
    "        if type(self.MSP.models[self.start]) != list:\n",
    "            names = [var.varname for var in self.MSP.models[self.start].getVars()]\n",
    "        else:\n",
    "            names = [var.varname for var in self.MSP.models[self.start][0].getVars()]\n",
    "        return names\n",
    "\n",
    "    def _get_first_stage_vars(self):\n",
    "        names = self._get_varname()\n",
    "        if self._type not in ['Markovian', 'Markov chain']:\n",
    "            vars = {name:self.extensive_model.getVarByName(name+'(0,)')\n",
    "                for name in names}\n",
    "        else:\n",
    "            vars = {name:self.extensive_model.getVarByName(name+'((0,),(0,))')\n",
    "                for name in names}\n",
    "        return vars\n",
    "\n",
    "    def _get_first_stage_states(self):\n",
    "        names = self._get_varname()\n",
    "        if self._type not in ['Markovian', 'Markov chain']:\n",
    "            states = {name:self.extensive_model.getVarByName(name+'(0,)')\n",
    "                for name in names}\n",
    "        else:\n",
    "            states = {name:self.extensive_model.getVarByName(name+'((0,),(0,))')\n",
    "                for name in names}\n",
    "        return states\n",
    "\n",
    "    @property\n",
    "    def first_stage_solution(self):\n",
    "        \"\"\"the obtained solution in the first stage\"\"\"\n",
    "        states = self._get_first_stage_states()\n",
    "        return {k:v.X for k,v in states.items()}\n",
    "\n",
    "    @property\n",
    "    def first_stage_all_solution(self):\n",
    "        vars = self._get_first_stage_vars()\n",
    "        return {k:v.X for k,v in vars.items()}\n",
    "\n",
    "    @property\n",
    "    def first_stage_cost(self):\n",
    "        vars = self._get_first_stage_vars()\n",
    "        return sum(v.obj*v.X for k,v in vars.items())\n",
    "\n",
    "    def _construct_extensive(self, flag_rolling):\n",
    "        ## Construct extensive model\n",
    "        MSP = self.MSP\n",
    "        T = MSP.T\n",
    "        start = self.start\n",
    "        n_Markov_states = MSP.n_Markov_states\n",
    "        n_samples = ([MSP.models[t].n_samples for t in range(T)] if n_Markov_states == 1 else [MSP.models[t][0].n_samples for t in range(T)])\n",
    "        n_states = MSP.n_states\n",
    "        # check if CTG variable is added or not\n",
    "        initial_model = (MSP.models[start] if n_Markov_states == 1 else MSP.models[start][0])\n",
    "        flag_CTG = 1 if initial_model.alpha is not None else -1\n",
    "        # |       stage 0       |        stage 1       | ... |       stage T-1      |\n",
    "        # |local_copies, states | local_copies, states | ... | local_copies, states |\n",
    "        # |local_copies,        | local_copies,        | ... | local_copies, states |\n",
    "        # extensive formulation only includes necessary variables\n",
    "        states = None\n",
    "        sample_paths = None\n",
    "        if flag_CTG == 1:\n",
    "            stage_cost = None\n",
    "        for t in reversed(range(start,T)):\n",
    "            M = [MSP.models[t]] if n_Markov_states == 1 else MSP.models[t]\n",
    "            # stage T-1 needs to add the states. sample path corresponds to\n",
    "            # current node.\n",
    "            if t == T-1:\n",
    "                _, sample_paths = MSP._enumerate_sample_paths(t,start,flag_rolling)\n",
    "                states = [self.extensive_model.addVars(sample_paths) for _ in range(n_states[t])]\n",
    "            # new_states is the local_copies. new_sample_paths corresponds to\n",
    "            # previous node\n",
    "            if t != start:\n",
    "                temp, new_sample_paths = MSP._enumerate_sample_paths(t-1,start,flag_rolling)\n",
    "                new_states = [self.extensive_model.addVars(new_sample_paths) for _ in range(n_states[t-1])]\n",
    "                if flag_CTG == 1:\n",
    "                    new_stage_cost = {new_sample_path: 0 for new_sample_path in new_sample_paths}\n",
    "            else:\n",
    "                new_states = [self.extensive_model.addVars(sample_paths) for _ in range(n_states[t])]\n",
    "\n",
    "            for j in range(n_samples[t]):\n",
    "                for k, m in enumerate(M):\n",
    "                    # copy information from model in scenario j and markov state\n",
    "                    # k.\n",
    "                    m._update_uncertainty(j)\n",
    "                    m.update()\n",
    "                    # compute sample paths that go through the current node\n",
    "                    current_sample_paths = ([item for item in sample_paths if item[0][t-start] == j and item[1][t-start] == k] if n_Markov_states != 1 else [item for item in sample_paths if item[t-start] == j])\n",
    "                    # when the sample path is too long, change the name of variables\n",
    "                    controls_ = m.controls\n",
    "                    states_ = m.states\n",
    "                    local_copies_ = m.local_copies\n",
    "                    controls_dict = {v: i for i, v in enumerate(controls_)}\n",
    "                    states_dict = {v: i for i, v in enumerate(states_)}\n",
    "                    local_copies_dict = {v: i for i, v in enumerate(local_copies_)}\n",
    "\n",
    "                    for current_sample_path in current_sample_paths:\n",
    "                        flag_reduced_name = 0\n",
    "                        if len(str(current_sample_path)) > 100:\n",
    "                            flag_reduced_name = 1\n",
    "                        if t != start:\n",
    "                            # compute sample paths that go through the\n",
    "                            # ancester node\n",
    "                            past_sample_path = (current_sample_path[:-1] if n_Markov_states == 1 else (current_sample_path[0][:-1],current_sample_path[1][:-1],))\n",
    "                        else:\n",
    "                            past_sample_path = current_sample_path\n",
    "\n",
    "                        if flag_CTG == -1 or t == start:\n",
    "                            weight = MSP.discount ** ((t - start)) * MSP._compute_weight_sample_path(current_sample_path, start)\n",
    "                        else:\n",
    "                            currentWeight = MSP._compute_current_weight_sample_path(current_sample_path)\n",
    "\n",
    "                        for i in range(n_states[t]):\n",
    "                            obj = (states_[i].obj * numpy.array(weight) if flag_CTG == -1 or t == start else 0)\n",
    "                            states[i][current_sample_path].lb = states_[i].lb\n",
    "                            states[i][current_sample_path].ub = states_[i].ub\n",
    "                            states[i][current_sample_path].obj = obj\n",
    "                            states[i][current_sample_path].vtype = states_[i].vtype\n",
    "                            if flag_reduced_name == 0:\n",
    "                                states[i][current_sample_path].varName = states_[i].varName + str(current_sample_path).replace(\" \", \"\")\n",
    "                            # cost-to-go update\n",
    "                            if t != start and flag_CTG == 1:\n",
    "                                new_stage_cost[past_sample_path] += (states[i][current_sample_path] * states_[i].obj * currentWeight)\n",
    "\n",
    "                        if t == start:\n",
    "                            for i in range(n_states[t]):\n",
    "                                new_states[i][current_sample_path].lb = local_copies_[i].lb\n",
    "                                new_states[i][current_sample_path].ub = local_copies_[i].ub\n",
    "                                new_states[i][current_sample_path].obj = local_copies_[i].obj\n",
    "                                new_states[i][current_sample_path].vtype = local_copies_[i].vtype\n",
    "                                if flag_reduced_name == 0:\n",
    "                                    new_states[i][current_sample_path].varName = local_copies_[i].varname + str(current_sample_path).replace(\" \", \"\")\n",
    "                        # copy local variables\n",
    "                        controls = [None for _ in range(len(controls_))]\n",
    "                        for i, var in enumerate(controls_):\n",
    "                            obj = (var.obj * weight if flag_CTG == -1 or t == start else 0)\n",
    "                            controls[i] = self.extensive_model.addVar(lb=var.lb,ub=var.ub,obj=obj,vtype=var.vtype,name=(var.varname + str(current_sample_path).replace(\" \", \"\") if flag_reduced_name == 0 else \"\"),)\n",
    "                            # cost-to-go update\n",
    "                            if t != start and flag_CTG == 1:\n",
    "                                new_stage_cost[past_sample_path] += (controls[i] * var.obj * currentWeight)\n",
    "                        # add constraints\n",
    "                        if t != T - 1 and flag_CTG == 1:\n",
    "                            self.extensive_model.addConstr(MSP.sense * (controls[controls_dict[m.getVarByName(\"alpha\")]] - stage_cost[current_sample_path]) >= 0)\n",
    "                        for constr_ in m.getConstrs():\n",
    "                            rhs_ = constr_.rhs\n",
    "                            expr_ = m.getRow(constr_)\n",
    "                            lhs = gurobipy.LinExpr()\n",
    "                            for i in range(expr_.size()):\n",
    "                                if expr_.getVar(i) in controls_dict.keys():\n",
    "                                    pos = controls_dict[expr_.getVar(i)]\n",
    "                                    lhs += expr_.getCoeff(i) * controls[pos]\n",
    "                                elif expr_.getVar(i) in states_dict.keys():\n",
    "                                    pos = states_dict[expr_.getVar(i)]\n",
    "                                    lhs += (expr_.getCoeff(i) * states[pos][current_sample_path])\n",
    "                                elif (expr_.getVar(i) in local_copies_dict.keys()):\n",
    "                                    pos = local_copies_dict[expr_.getVar(i)]\n",
    "                                    if t != start:\n",
    "                                        lhs += (expr_.getCoeff(i) * new_states[pos][past_sample_path])\n",
    "                                    else:\n",
    "                                        lhs += (expr_.getCoeff(i) * new_states[pos][current_sample_path])\n",
    "                            self.extensive_model.addConstr(lhs=lhs, sense=constr_.sense, rhs=rhs_)\n",
    "            states = new_states\n",
    "            if flag_CTG == 1:\n",
    "                stage_cost = new_stage_cost\n",
    "            sample_paths = new_sample_paths\n",
    "\n",
    "\n",
    "class Rolling(object):\n",
    "\n",
    "    def __init__(self, MSP):\n",
    "        self.MSP = MSP\n",
    "\n",
    "    def solve_single_process(self, a, jobs, query, query_stage_cost, solution,stage_cost, seed):\n",
    "        MSP = self.MSP\n",
    "        # random_state for simulations\n",
    "        another_random_state = numpy.random.RandomState([2**32-1, jobs[0]])\n",
    "        Markov_states = transition_matrix = n_samples = None\n",
    "        if MSP._type == 'Markovian':\n",
    "            markovian_samples = MSP.Markovian_uncertainty(another_random_state,len(jobs))\n",
    "            Markov_states = [None for t in range(MSP.T)]\n",
    "            transition_matrix = [None for t in range(MSP.T)]\n",
    "        for i,j in enumerate(jobs):\n",
    "            # random_state for discretization\n",
    "            random_state = check_random_state(seed)\n",
    "            for cur in range(MSP.T-1):\n",
    "                if MSP._type == \"Markovian\":\n",
    "                    Markov_states[cur] = markovian_samples[i][cur].reshape(1,-1)\n",
    "                    Markov_states[cur+1] = numpy.array([self.conditional_dist(random_state=random_state,prev=markovian_samples[i][cur],t=cur+1,) for _ in range(self.n_branches)])\n",
    "                    for t in range(cur+2,MSP.T):\n",
    "                        Markov_states[t] = numpy.array([self.conditional_dist(random_state=random_state,prev=Markov_states[t-1][k],t=t,) for k in range(self.n_branches)])\n",
    "                    transition_matrix[cur] = numpy.array([[1]])\n",
    "                    transition_matrix[cur+1] = numpy.ones((1,self.n_branches))/self.n_branches\n",
    "                    for t in range(cur+2,MSP.T):\n",
    "                        transition_matrix[t] = numpy.eye(self.n_branches)\n",
    "                if MSP[cur]._type == 'continuous':\n",
    "                    MSP[cur]._sample_uncertainty(another_random_state)\n",
    "                    MSP[cur]._flag_discrete = 1\n",
    "                if MSP[cur+1]._type == 'continuous':\n",
    "                    n_samples = [1] * MSP.T\n",
    "                    n_samples[cur+1] = self.n_branches\n",
    "\n",
    "                MSP.discretize(n_samples=n_samples,random_state=random_state,replace=True,method='input',Markov_states=Markov_states,transition_matrix=transition_matrix,int_flag=0)\n",
    "                ext = Extensive(MSP)\n",
    "                ext.solve(outputFlag=0, start=cur, flag_rolling=1)\n",
    "                if query is not None:\n",
    "                    sol = ext.first_stage_all_solution\n",
    "                    for k,v in sol.items():\n",
    "                        if k in query:\n",
    "                            solution[k][j][cur] = v\n",
    "                if query_stage_cost:\n",
    "                    stage_cost[j][cur] = ext.first_stage_cost\n",
    "                a[j] += MSP.discount ** cur * ext.first_stage_cost\n",
    "                MSP._reverse_discretize()\n",
    "                MSP[cur]._delete_link_constrs()\n",
    "                MSP[cur+1]._set_up_link_constrs()\n",
    "                MSP[cur+1]._update_link_constrs([ext.first_stage_solution[v.varName] for v in MSP[cur+1].states])\n",
    "            if MSP[-1]._type == 'continuous':\n",
    "                MSP[-1]._sample_uncertainty(another_random_state)\n",
    "            if MSP._type == 'Markovian':\n",
    "                MSP[-1]._update_uncertainty_dependent(markovian_samples[i][-1])\n",
    "            MSP[-1].optimize()\n",
    "            MSP[-1]._delete_link_constrs()\n",
    "            a[j] += MSP.discount ** (MSP.T-1) * MSP[-1].objVal\n",
    "            for var in MSP[-1].getVars():\n",
    "                if var.varname in query:\n",
    "                    solution[var.varname][j][MSP.T-1] = var.X\n",
    "            if query_stage_cost:\n",
    "                stage_cost[j][MSP.T-1] = MSP[-1].objVal\n",
    "\n",
    "\n",
    "    def solve(self,n_simulations,n_branches,conditional_dist=None,n_processes=1,percentile=95,query=None,query_stage_cost=False,random_state=None,):\n",
    "        \"\"\"Call rolling solver to solve the true problem. It will dynamically\n",
    "        construct extensive models and then call Gurobi solver to solve it.\n",
    "        \"\"\"\n",
    "        self.n_simulations = n_simulations\n",
    "        self.n_branches = n_branches\n",
    "        if self.MSP._type == 'Markovian':\n",
    "            if conditional_dist is None:\n",
    "                raise Exception(\"Conditional distribution must be given for \"+\"Markovian problem!\")\n",
    "        self.conditional_dist = conditional_dist\n",
    "        a = multiprocessing.Array(\"d\", [0] * n_simulations)\n",
    "        procs = [None] * n_processes\n",
    "        jobs = allocate_jobs(n_simulations, n_processes)\n",
    "        query = query if query is not None else []\n",
    "        solution = stage_cost = None\n",
    "        if query is not None:\n",
    "            solution = {item: [multiprocessing.RawArray(\"d\",[0] * (self.MSP.T)) for _ in range(n_simulations)] for item in query}\n",
    "        if query_stage_cost:\n",
    "            stage_cost = [multiprocessing.RawArray(\"d\",[0] * (self.MSP.T)) for _ in range(n_simulations)]\n",
    "        for p in range(n_processes):\n",
    "            procs[p] = multiprocessing.Process(target=self.solve_single_process,args=(a,jobs[p],query,query_stage_cost,solution,stage_cost,random_state))\n",
    "            procs[p].start()\n",
    "        for proc in procs:\n",
    "            proc.join()\n",
    "        if query is not None:\n",
    "            self.solution = {k: pandas.DataFrame(numpy.array(v)) for k, v in solution.items()}\n",
    "        if query_stage_cost:\n",
    "            self.stage_cost = pandas.DataFrame(numpy.array(stage_cost))\n",
    "        self.pv = [item for item in a]\n",
    "        if self.n_simulations != 1:\n",
    "            self.CI = compute_CI(self.pv, percentile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AssetMgt.discretize(n_samples=100, method='input', Markov_states=Markov_states, transition_matrix=transition_matrix, random_state=888,)\n",
    "AssetMgt.set_AVaR(l=0.5, a=0.25)\n",
    "AssetMgt_SDDP = SDDP(AssetMgt)\n",
    "AssetMgt_SDDP.solve(max_iterations=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
