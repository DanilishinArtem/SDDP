{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import pandas\n",
    "from discretize import generator, MarkovSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of stages:\n",
    "T = 3\n",
    "# number of assets:\n",
    "N = 3\n",
    "# risk free interest rate:\n",
    "rf = 0.0005\n",
    "# additional dataset:\n",
    "fee = 0.001\n",
    "# size of MC:\n",
    "size = 25\n",
    " \n",
    "coeffs = pandas.read_csv(\"./data/coefficients.csv\",index_col=0)\n",
    "beta = torch.tensor(coeffs['beta'])\n",
    "\n",
    "alpha = torch.tensor(coeffs['alpha'])\n",
    "beta = torch.tensor(coeffs['beta'])\n",
    "sigma = torch.tensor(coeffs['epsilon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(alpha,sigma):\n",
    "    def inner(random_state):\n",
    "        return random_state.normal.Normal(alpha+1,sigma).sample()\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented Markovian process generator\n",
    "def generator_augmented(random_state, size, T):\n",
    "    # (r_it, r_Mt, epsilon_Mt, sigma^2_Mt)\n",
    "    process = generator(random_state, size, T)\n",
    "    market_return = process[:,:,0]\n",
    "    process_aug = torch.cat((beta[:N]*(market_return[:,:,numpy.newaxis]-rf) + rf,process),axis=-1,)\n",
    "    return process_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markov chain discretization\n",
    "sample_paths = generator(torch.distributions,size=1000, T=T)\n",
    "return_sample_paths = sample_paths[:,:,0]\n",
    "var_sample_paths = sample_paths[:,:,2]\n",
    "price_sample_paths = torch.cumprod(torch.exp(return_sample_paths),axis=1)\n",
    "markovian = MarkovSampler(generator,n_Markov_states=[1]+[100]*(T-1),n_sample_paths=size)\n",
    "markovian.SA()\n",
    "# augment to N+3 dimension\n",
    "Markov_states = [None for _ in range(T)]\n",
    "transition_matrix = markovian.transition_matrix\n",
    "for t in range(T):\n",
    "    market_return = markovian.Markov_states[t][:,0].reshape(-1,1)\n",
    "    asset_return_market_exposure = beta[:N]*(market_return-rf) + rf\n",
    "    Markov_states[t] = torch.cat((asset_return_market_exposure,markovian.Markov_states[t]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy\n",
    "from statistics_ import rand_int,check_random_state\n",
    "from exception import SampleSizeError,DistributionError\n",
    "from measure import Expectation\n",
    "import copy_ as deepcopy\n",
    "from collections import abc\n",
    "from numbers import Number\n",
    "import time\n",
    "import math\n",
    "\n",
    "class StochasticModel(object):\n",
    "    \"\"\"The StochasticModel class\"\"\"\n",
    "    def __init__(self, name=\"\"):\n",
    "        self._model = gurobipy.Model(env=gurobipy.Env(), name=name)\n",
    "        # each and every instance must have state variables, local copy variables\n",
    "        self.states = []\n",
    "        self.local_copies = []\n",
    "        # (discretized) uncertainties\n",
    "        # stage-wise independent discrete uncertainties\n",
    "        self.uncertainty_rhs = {}\n",
    "        self.uncertainty_coef = {}\n",
    "        self.uncertainty_obj = {}\n",
    "        # indices of stage-dependent uncertainties\n",
    "        self.uncertainty_rhs_dependent = {}\n",
    "        self.uncertainty_coef_dependent = {}\n",
    "        self.uncertainty_obj_dependent = {}\n",
    "        # true uncertainties\n",
    "        # stage-wise independent true continuous uncertainties\n",
    "        self.uncertainty_rhs_continuous = {}\n",
    "        self.uncertainty_coef_continuous = {}\n",
    "        self.uncertainty_obj_continuous = {}\n",
    "        self.uncertainty_mix_continuous = {}\n",
    "        # stage-wise independent true discrete uncertainties\n",
    "        self.uncertainty_rhs_discrete = {}\n",
    "        self.uncertainty_coef_discrete = {}\n",
    "        self.uncertainty_obj_discrete = {}\n",
    "        # cutting planes approximation of recourse variable alpha\n",
    "        self.alpha = None\n",
    "        self.cuts = []\n",
    "        # linking constraints\n",
    "        self.link_constrs = []\n",
    "        # number of discrete uncertainties\n",
    "        self.n_samples = 1\n",
    "        # number of state varibles\n",
    "        self.n_states = 0\n",
    "        # probability measure for discrete uncertainties\n",
    "        self.probability = None\n",
    "        # type of true problem: continuous/discrete\n",
    "        self._type = None\n",
    "        # flag to indicate discretization of true problem\n",
    "        self._flag_discrete = 0\n",
    "        # collection of all specified dim indices of Markovian uncertainties\n",
    "        self.Markovian_dim_index = []\n",
    "        # risk measure\n",
    "        self.measure = Expectation\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            return getattr(self._model, name)\n",
    "        except AttributeError:\n",
    "            raise AttributeError(\"no attribute named {}\".format(name))\n",
    "\n",
    "    def addStateVars(\n",
    "            self,\n",
    "            *indices,\n",
    "            lb=0.0,\n",
    "            ub=1e+100,\n",
    "            obj=0.0,\n",
    "            vtype='C',\n",
    "            name=\"\",\n",
    "            uncertainty=None,\n",
    "            uncertainty_dependent=None\n",
    "    ):\n",
    "        # Add state variables in bulk. Generalize gurobipy.addVars() to\n",
    "        # incorporate uncertainty in the objective function. Variables are added\n",
    "        # as state variables and the corresponding local copy variables will be\n",
    "        # added behind the scene\n",
    "\n",
    "        state = self._model.addVars(\n",
    "            *indices, lb=lb, ub=ub, obj=obj, vtype=vtype, name=name\n",
    "        )\n",
    "        local_copy = self._model.addVars(\n",
    "            *indices, lb=lb, ub=ub, name=name + \"_local_copy\"\n",
    "        )\n",
    "        self._model.update()\n",
    "        self.states += state.values()\n",
    "        self.local_copies += local_copy.values()\n",
    "        self.n_states += len(state)\n",
    "\n",
    "        if uncertainty is not None:\n",
    "            uncertainty = self._check_uncertainty(uncertainty, 0, len(state))\n",
    "            if callable(uncertainty):\n",
    "                self.uncertainty_obj_continuous[\n",
    "                    tuple(state.values())\n",
    "                ] = uncertainty\n",
    "            else:\n",
    "                self.uncertainty_obj[tuple(state.values())] = uncertainty\n",
    "\n",
    "\n",
    "        if uncertainty_dependent is not None:\n",
    "            uncertainty_dependent = self._check_uncertainty_dependent(\n",
    "                uncertainty_dependent, 0, len(state)\n",
    "            )\n",
    "            self.uncertainty_obj_dependent[\n",
    "                tuple(state.values())\n",
    "            ] = uncertainty_dependent\n",
    "\n",
    "        return state, local_copy\n",
    "    \n",
    "    def addVars(\n",
    "            self,\n",
    "            *indices,\n",
    "            lb=0.0,\n",
    "            ub=1e+100,\n",
    "            obj=0.0,\n",
    "            vtype='C',\n",
    "            name=\"\",\n",
    "            uncertainty=None,\n",
    "            uncertainty_dependent=None\n",
    "    ):\n",
    "        # Add variables in bulk. Generalize gurobipy.addVars() to\n",
    "        # incorporate uncertainty in the objective function\n",
    "\n",
    "        var = self._model.addVars(\n",
    "            *indices, lb=lb, ub=ub, obj=obj, vtype=vtype, name=name\n",
    "        )\n",
    "        self._model.update()\n",
    "\n",
    "        if uncertainty is not None:\n",
    "            uncertainty = self._check_uncertainty(uncertainty, 0, len(var))\n",
    "            if callable(uncertainty):\n",
    "                self.uncertainty_obj_continuous[\n",
    "                    tuple(var.values())\n",
    "                ] = uncertainty\n",
    "            else:\n",
    "                self.uncertainty_obj[tuple(var.values())] = uncertainty\n",
    "\n",
    "        if uncertainty_dependent is not None:\n",
    "            uncertainty_dependent = self._check_uncertainty_dependent(\n",
    "                uncertainty_dependent, 0, len(var)\n",
    "            )\n",
    "            self.uncertainty_obj_dependent[\n",
    "                tuple(var.values())\n",
    "            ] = uncertainty_dependent\n",
    "\n",
    "        return var\n",
    "    \n",
    "    def addConstrs(\n",
    "        self, generator, name=\"\", uncertainty=None, uncertainty_dependent=None\n",
    "    ):\n",
    "        # to incorporate uncertainty on the RHS of the constraints.\n",
    "        # If you want to add constraints with uncertainties on coefficients,\n",
    "        # use addConstr() instead and add those constraints one by one\n",
    "        constr = self._model.addConstrs(generator, name=name)\n",
    "        self._model.update()\n",
    "\n",
    "        if uncertainty is not None:\n",
    "            uncertainty = self._check_uncertainty(uncertainty, 0, len(constr))\n",
    "            if callable(uncertainty):\n",
    "                self.uncertainty_rhs_continuous[\n",
    "                    tuple(constr.values())\n",
    "                ] = uncertainty\n",
    "            else:\n",
    "                self.uncertainty_rhs[tuple(constr.values())] = uncertainty\n",
    "\n",
    "        if uncertainty_dependent is not None:\n",
    "            uncertainty_dependent = self._check_uncertainty_dependent(\n",
    "                uncertainty_dependent, 0, len(constr)\n",
    "            )\n",
    "            self.uncertainty_rhs_dependent[\n",
    "                tuple(constr.values())\n",
    "            ] = uncertainty_dependent\n",
    "\n",
    "        return constr\n",
    "    \n",
    "    def addConstr(\n",
    "            self,\n",
    "            lhs,\n",
    "            sense=None,\n",
    "            rhs=None,\n",
    "            name=\"\",\n",
    "            uncertainty=None,\n",
    "            uncertainty_dependent=None,\n",
    "    ):\n",
    "        # Add a constraint to the model. Generalize gurobipy.addConstr()\n",
    "        # to incorporate uncertainty in a constraint\n",
    "        constr = self._model.addConstr(lhs, sense=sense, rhs=rhs, name=name)\n",
    "        self._model.update()\n",
    "\n",
    "        if uncertainty is not None:\n",
    "            uncertainty = self._check_uncertainty(uncertainty, 1, 1)\n",
    "            for key, value in uncertainty.items():\n",
    "                # key can be a gurobipy.Var or \"rhs\"\n",
    "                # Append constr to the key\n",
    "                if type(key) == gurobipy.Var:\n",
    "                    if callable(value):\n",
    "                        self.uncertainty_coef_continuous[(constr, key)] = value\n",
    "                    else:\n",
    "                        self.uncertainty_coef[(constr, key)] = value\n",
    "                elif type(key) == str and key.lower() == \"rhs\":\n",
    "                    if callable(value):\n",
    "                        self.uncertainty_rhs_continuous[constr] = value\n",
    "                    else:\n",
    "                        self.uncertainty_rhs[constr] = value\n",
    "                else:\n",
    "                    raise ValueError(\"wrong uncertainty key!\")\n",
    "\n",
    "        if uncertainty_dependent is not None:\n",
    "            uncertainty_dependent = self._check_uncertainty_dependent(\n",
    "                uncertainty_dependent, 1, 1\n",
    "            )\n",
    "            for key, value in uncertainty_dependent.items():\n",
    "                # key can be a gurobipy.Var or \"rhs\"\n",
    "                # Append constr to the key\n",
    "                if type(key) == gurobipy.Var:\n",
    "                    if not any(key is item for item in self._model.getVars()):\n",
    "                        raise ValueError(\"wrong uncertainty key!\")\n",
    "                    self.uncertainty_coef_dependent[(constr, key)] = value\n",
    "                elif type(key) == str and key.lower() == \"rhs\":\n",
    "                    self.uncertainty_rhs_dependent[constr] = value\n",
    "                else:\n",
    "                    raise ValueError(\"wrong uncertainty key!\")\n",
    "\n",
    "        return constr\n",
    "    \n",
    "    def _check_uncertainty_dependent(\n",
    "        self, uncertainty_dependent, flag_dict, list_dim\n",
    "    ):\n",
    "        # Make sure the input uncertainty location index is in the correct form.\n",
    "        # Return a copied uncertainty to avoid making changes to mutable object\n",
    "        # given by the users.\n",
    "        if isinstance(uncertainty_dependent, abc.Mapping):\n",
    "            if flag_dict == 0:\n",
    "                raise TypeError(\"wrong uncertainty_dependent format!\")\n",
    "            for key, item in uncertainty_dependent.items():\n",
    "                try:\n",
    "                    item = int(item)\n",
    "                    uncertainty_dependent[key] = item\n",
    "                except (TypeError,ValueError):\n",
    "                    raise ValueError(\"location index of individual component \\\n",
    "                                     of uncertainty_dependent must be integer!\")\n",
    "                self.Markovian_dim_index.append(item)\n",
    "\n",
    "        elif isinstance(uncertainty_dependent, (abc.Sequence, torch.Tensor)):\n",
    "            uncertainty_dependent = list(uncertainty_dependent)\n",
    "            if len(uncertainty_dependent) != list_dim:\n",
    "                raise ValueError(\n",
    "                    \"dimension of the scenario is {} while \\\n",
    "                    dimension of added object is {}!\"\n",
    "                    .format(len(uncertainty_dependent), list_dim)\n",
    "                )\n",
    "            self.Markovian_dim_index += uncertainty_dependent\n",
    "\n",
    "        elif isinstance(uncertainty_dependent, Number):\n",
    "            uncertainty_dependent = int(uncertainty_dependent)\n",
    "            if list_dim != 1:\n",
    "                raise ValueError(\n",
    "                    \"dimension of the scenario is 1 while \\\n",
    "                    dimension of added object is {}!\"\n",
    "                    .format(list_dim)\n",
    "                )\n",
    "            self.Markovian_dim_index.append(uncertainty_dependent)\n",
    "        else:\n",
    "            raise TypeError(\"wrong uncertainty_dependent format\")\n",
    "        return uncertainty_dependent\n",
    "    \n",
    "    def _check_uncertainty(self, uncertainty, flag_dict, list_dim):\n",
    "        # Make sure the input uncertainty is in the correct form. Return a\n",
    "        # copied uncertainty to avoid making changes to mutable object given by\n",
    "        # the users.\n",
    "        if isinstance(uncertainty, abc.Mapping):\n",
    "            uncertainty = dict(uncertainty)\n",
    "            for key, item in uncertainty.items():\n",
    "                if callable(item):\n",
    "                    if not self._type:\n",
    "                        # add uncertainty for the first time\n",
    "                        self._type = \"continuous\"\n",
    "                    else:\n",
    "                        # already added uncertainty\n",
    "                        if self._type != \"continuous\":\n",
    "                            raise SampleSizeError(\n",
    "                                self._model.modelName,\n",
    "                                self.n_samples,\n",
    "                                uncertainty,\n",
    "                                \"infinite\"\n",
    "                            )\n",
    "                    try:\n",
    "                        item(torch.distributions)\n",
    "                    except TypeError:\n",
    "                        raise DistributionError(arg=False)\n",
    "                    try:\n",
    "                        float(item(torch.distributions))\n",
    "                    except (ValueError,TypeError):\n",
    "                        raise DistributionError(ret=False)\n",
    "                else:\n",
    "                    try:\n",
    "                        item = torch.tensor(item, dtype=torch.float64)\n",
    "                    except ValueError:\n",
    "                        raise ValueError(\"Scenarios must only contains numbers!\")\n",
    "                    if item.ndim != 1:\n",
    "                        raise ValueError(\n",
    "                            \"dimension of the distribution is {} while \\\n",
    "                            dimension of the added object is {}!\"\n",
    "                            .format(item.ndim, 1)\n",
    "                        )\n",
    "                    uncertainty[key] = list(item)\n",
    "\n",
    "                    if not self._type:\n",
    "                        # add uncertainty for the first time\n",
    "                        self._type = \"discrete\"\n",
    "                        self.n_samples = len(item)\n",
    "                    else:\n",
    "                        # already added uncertainty\n",
    "                        if self._type != \"discrete\":\n",
    "                            raise SampleSizeError(\n",
    "                                self._model.modelName,\n",
    "                                \"infinite\",\n",
    "                                {key:item},\n",
    "                                len(item)\n",
    "                            )\n",
    "                        if self.n_samples != len(item):\n",
    "                            raise SampleSizeError(\n",
    "                                self._model.modelName,\n",
    "                                self.n_samples,\n",
    "                                {key:item},\n",
    "                                len(item)\n",
    "                            )\n",
    "            if flag_dict == 0:\n",
    "                raise TypeError(\"wrong uncertainty format!\")\n",
    "        elif isinstance(uncertainty, abc.Callable):\n",
    "            try:\n",
    "                sample = uncertainty(torch.distributions)\n",
    "            except TypeError:\n",
    "                raise DistributionError(arg=False)\n",
    "            if list_dim == 1:\n",
    "                try:\n",
    "                    float(sample)\n",
    "                except (ValueError,TypeError):\n",
    "                    raise DistributionError(ret=False)\n",
    "            else:\n",
    "                try:\n",
    "                    sample = [float(item) for item in sample]\n",
    "                except (ValueError,TypeError):\n",
    "                    raise DistributionError(ret=False)\n",
    "                if list_dim != len(uncertainty(torch.distributions)):\n",
    "                    raise ValueError(\n",
    "                        \"dimension of the distribution is {} while \\\n",
    "                        dimension of the added object is {}!\"\n",
    "                        .format(len(uncertainty(torch.distributions)), list_dim)\n",
    "                    )\n",
    "            if not self._type:\n",
    "                # add uncertainty for the first time\n",
    "                self._type = \"continuous\"\n",
    "            else:\n",
    "                # already added uncertainty\n",
    "                if self._type != \"continuous\":\n",
    "                    raise SampleSizeError(\n",
    "                        self._model.modelName,\n",
    "                        self.n_samples,\n",
    "                        uncertainty,\n",
    "                        \"infinite\"\n",
    "                    )\n",
    "        elif isinstance(uncertainty, (abc.Sequence, torch.Tensor)):\n",
    "            uncertainty = torch.tensor(uncertainty)\n",
    "            if list_dim == 1:\n",
    "                if uncertainty.ndim != 1:\n",
    "                    raise ValueError(\"dimension of the scenarios is {} while \\\n",
    "                                     dimension of the added object is 1!\"\n",
    "                        .format(uncertainty.ndim)\n",
    "                    )\n",
    "                try:\n",
    "                    uncertainty = [float(item) for item in uncertainty]\n",
    "                except ValueError:\n",
    "                    raise ValueError(\"Scenarios must only contains numbers!\")\n",
    "            else:\n",
    "                # list to list\n",
    "                if uncertainty.ndim != 2 or uncertainty.shape[1] != list_dim:\n",
    "                    dim = None if uncertainty.ndim == 1 else uncertainty.shape[1]\n",
    "                    raise ValueError(\"dimension of the scenarios is {} while \\\n",
    "                                     dimension of the added object is 1!\"\n",
    "                        .format(dim, uncertainty.ndim)\n",
    "                    )\n",
    "                try:\n",
    "                    uncertainty = torch.tensor(uncertainty, dtype=torch.float64)\n",
    "                except ValueError:\n",
    "                    raise ValueError(\"Scenarios must only contains numbers!\")\n",
    "                uncertainty = [list(item) for item in uncertainty]\n",
    "            if not self._type:\n",
    "                self._type = \"discrete\"\n",
    "                self.n_samples = len(uncertainty)\n",
    "            else:\n",
    "                if self._type != \"discrete\":\n",
    "                    raise SampleSizeError(\n",
    "                        self._model.modelName,\n",
    "                        \"infinite\",\n",
    "                        uncertainty,\n",
    "                        len(uncertainty)\n",
    "                    )\n",
    "                if self.n_samples != len(uncertainty):\n",
    "                    raise SampleSizeError(\n",
    "                        self._model.modelName,\n",
    "                        self.n_samples,\n",
    "                        uncertainty,\n",
    "                        len(uncertainty)\n",
    "                    )\n",
    "        else:\n",
    "            raise TypeError(\"wrong uncertainty format!\")\n",
    "\n",
    "        return uncertainty\n",
    "    \n",
    "    def _discretize(self, n_samples, random_state, replace=True):\n",
    "        # Discretize stage-wise independent continuous uncertainties.\n",
    "        if hasattr(self,'_flag_discrete') and self._flag_discrete == 1: return\n",
    "        # Discretize continuous true problem\n",
    "        if self._type == \"continuous\":\n",
    "            self.n_samples = n_samples\n",
    "            # Order of discretization matters\n",
    "            for key, dist in sorted(\n",
    "                self.uncertainty_rhs_continuous.items(),\n",
    "                key=lambda t: repr(t[0]),\n",
    "            ):\n",
    "                self.uncertainty_rhs[key] = [\n",
    "                    dist(random_state) for _ in range(self.n_samples)\n",
    "                ]\n",
    "            for key, dist in sorted(\n",
    "                self.uncertainty_obj_continuous.items(),\n",
    "                key=lambda t: repr(t[0]),\n",
    "            ):\n",
    "                self.uncertainty_obj[key] = [\n",
    "                    dist(random_state) for _ in range(self.n_samples)\n",
    "                ]\n",
    "            for key, dist in sorted(\n",
    "                self.uncertainty_coef_continuous.items(),\n",
    "                key=lambda t: repr(t[0]),\n",
    "            ):\n",
    "                self.uncertainty_coef[key] = [\n",
    "                    dist(random_state) for _ in range(self.n_samples)\n",
    "                ]\n",
    "            for keys, dist in sorted(\n",
    "                self.uncertainty_mix_continuous.items(),\n",
    "                key=lambda t: repr(t[0]),\n",
    "            ):\n",
    "                for i in range(self.n_samples):\n",
    "                    sample = dist(random_state)\n",
    "                    for index, key in enumerate(keys):\n",
    "                        if type(key) == gurobipy.Var:\n",
    "                            if key not in self.uncertainty_obj.keys():\n",
    "                                self.uncertainty_obj[key] = [sample[index]]\n",
    "                            else:\n",
    "                                self.uncertainty_obj[key].append(sample[index])\n",
    "                        elif type(key) == gurobipy.Constr:\n",
    "                            if key not in self.uncertainty_rhs.keys():\n",
    "                                self.uncertainty_rhs[key] = [sample[index]]\n",
    "                            else:\n",
    "                                self.uncertainty_rhs[key].append(sample[index])\n",
    "                        else:\n",
    "                            if key not in self.uncertainty_coef.keys():\n",
    "                                self.uncertainty_coef[key] = [sample[index]]\n",
    "                            else:\n",
    "                                self.uncertainty_coef[key].append(\n",
    "                                    sample[index]\n",
    "                                )\n",
    "        # Discretize discrete true problem\n",
    "        else:\n",
    "            if n_samples > self.n_samples:\n",
    "                raise Exception(\n",
    "                    \"n_samples should be smaller than the total number of samples!\"\n",
    "                )\n",
    "            for key, samples in sorted(\n",
    "                self.uncertainty_rhs.items(), key=lambda t: repr(t[0])\n",
    "            ):\n",
    "                self.uncertainty_rhs_discrete[key] = samples\n",
    "                # numpy.random.choice does not work on multi-dimensional arrays\n",
    "                drawed_indices = rand_int(\n",
    "                    self.n_samples,\n",
    "                    random_state,\n",
    "                    size=n_samples,\n",
    "                    probability=self.probability,\n",
    "                    replace=replace,\n",
    "                )\n",
    "                self.uncertainty_rhs[key] = [\n",
    "                    samples[index]\n",
    "                    for index in drawed_indices\n",
    "                ]\n",
    "            for key, samples in sorted(\n",
    "                self.uncertainty_obj.items(), key=lambda t: repr(t[0])\n",
    "            ):\n",
    "                self.uncertainty_obj_discrete[key] = samples\n",
    "                drawed_indices = rand_int(\n",
    "                    self.n_samples,\n",
    "                    random_state,\n",
    "                    size=n_samples,\n",
    "                    probability=self.probability,\n",
    "                    replace=replace,\n",
    "                )\n",
    "                self.uncertainty_obj[key] = [\n",
    "                    samples[index]\n",
    "                    for index in drawed_indices\n",
    "                ]\n",
    "            for key, samples in sorted(\n",
    "                self.uncertainty_coef.items(), key=lambda t: repr(t[0])\n",
    "            ):\n",
    "                self.uncertainty_coef_discrete[key] = samples\n",
    "                drawed_indices = rand_int(\n",
    "                    self.n_samples,\n",
    "                    random_state,\n",
    "                    size=n_samples,\n",
    "                    probability=self.probability,\n",
    "                    replace=replace,\n",
    "                )\n",
    "                self.uncertainty_coef[key] = [\n",
    "                    samples[index]\n",
    "                    for index in drawed_indices\n",
    "                ]\n",
    "            self.n_samples_discrete = self.n_samples\n",
    "            self.n_samples = n_samples\n",
    "        self._flag_discrete = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy\n",
    "from itertools import product\n",
    "import numpy\n",
    "import pandas\n",
    "from statistics_ import check_random_state\n",
    "from statistics_ import check_Markovian_uncertainty\n",
    "from statistics_ import check_Markov_states_and_transition_matrix\n",
    "from exception import MarkovianDimensionError\n",
    "from collections import abc\n",
    "import numbers\n",
    "import math\n",
    "\n",
    "\n",
    "class MSLP(object):\n",
    "    # A multistage stochastic linear program composed of a sequence of StochasticModels.\n",
    "    def __init__(\n",
    "            self,\n",
    "            size,\n",
    "            T,\n",
    "            bound=None,\n",
    "            sense=1,\n",
    "            outputFlag=0,\n",
    "            discount=1.0,\n",
    "            ctg=False,\n",
    "            **kwargs):\n",
    "        if (T < 2\n",
    "                or discount > 1\n",
    "                or discount < 0\n",
    "                or sense not in [-1, 1]\n",
    "                or outputFlag not in [0, 1]):\n",
    "            raise Exception('Arguments of SDDP construction are not valid!')\n",
    "\n",
    "        self.T = T\n",
    "        self.size = size\n",
    "        self.discount = discount\n",
    "        self.bound = bound\n",
    "        self.sense = sense\n",
    "        self.n_Markov_states = 1\n",
    "        self.dim_Markov_states = {}\n",
    "        self.measure = 'risk neutral'\n",
    "        self._type = 'stage-wise independent'\n",
    "        self._individual_type = 'original'\n",
    "        self._set_up_default_bound()\n",
    "        self._set_up_model()\n",
    "        self._set_up_model_attr(sense, outputFlag, kwargs)\n",
    "        self._flag_discrete = 0\n",
    "        self._flag_update = 0\n",
    "        self.db = None\n",
    "        self._flag_infinity = 0\n",
    "        if ctg: self._set_up_CTG()\n",
    "\n",
    "    def __repr__(self):\n",
    "        sense = 'Minimization' if self.sense == 1 else 'Maximization'\n",
    "        string = (\"<SDDP instance {} {} {} problem, {} stages, \"\n",
    "            + \"{} discount, {} known bound>\")\n",
    "        return string.format(sense, self.measure, self._type, self.T,\n",
    "            self.discount, self.bound)\n",
    "\n",
    "    def __getitem__(self, t):\n",
    "        return self.models[t]\n",
    "\n",
    "    def _set_up_default_bound(self):\n",
    "        if self.bound is None:\n",
    "            self.bound = -1000000000 if self.sense == 1 else 1000000000\n",
    "\n",
    "    def _set_up_model(self):\n",
    "        self.models = [StochasticModel(name=str(t)) for t in range(self.T)]\n",
    "\n",
    "    def _set_up_model_attr(self, sense, outputFlag, kwargs):\n",
    "        for t in range(self.T):\n",
    "            m = self.models[t]\n",
    "            m.Params.outputFlag = outputFlag\n",
    "            m.setAttr('modelsense', sense)\n",
    "            for k,v in kwargs.items():\n",
    "                m.setParam(k,v)\n",
    "\n",
    "    def add_Markovian_uncertainty(self, Markovian_uncertainty):\n",
    "        # Add a Markovian continuous process.\n",
    "\n",
    "        if hasattr(self, \"Markovian_uncertainty\") or hasattr(self,\n",
    "        \"Markov_states\"):\n",
    "            raise ValueError(\"Markovian uncertainty has already added!\")\n",
    "        self.dim_Markov_states=check_Markovian_uncertainty(Markovian_uncertainty\n",
    "        ,self.size,self.T)\n",
    "        self.Markovian_uncertainty = Markovian_uncertainty\n",
    "        self._type = 'Markovian'\n",
    "\n",
    "    def discretize(\n",
    "            self,\n",
    "            n_samples=None,\n",
    "            random_state=None,\n",
    "            replace=True,\n",
    "            n_Markov_states=None,\n",
    "            method='SA',\n",
    "            n_sample_paths=None,\n",
    "            Markov_states=None,\n",
    "            transition_matrix=None,\n",
    "            int_flag=0):\n",
    "        # Discretize Markovian continuous uncertainty by k-means or (robust)\n",
    "        # stochasitic approximation.\n",
    "\n",
    "        if n_samples is not None:\n",
    "            if isinstance(n_samples, (numbers.Integral, torch.int)):\n",
    "                if n_samples < 1:\n",
    "                    raise ValueError(\"n_samples should be bigger than zero!\")\n",
    "                n_samples = (\n",
    "                    [1]\n",
    "                    +[n_samples] * (self.T-1)\n",
    "                )\n",
    "            elif isinstance(n_samples, (abc.Sequence, torch.Tensor)):\n",
    "                if len(n_samples) != self.T:\n",
    "                    raise ValueError(\n",
    "                        \"n_samples list should be of length {} rather than {}!\"\n",
    "                        .format(self.T,len(n_samples))\n",
    "                    )\n",
    "                if n_samples[0] != 1:\n",
    "                    raise ValueError(\n",
    "                        \"The first stage model should be deterministic!\"\n",
    "                    )\n",
    "            else:\n",
    "                raise ValueError(\"Invalid input of n_samples!\")\n",
    "            # discretize stage-wise independent continuous distribution\n",
    "            random_state = check_random_state(random_state)\n",
    "            for t in range(1,self.T):\n",
    "                self.models[t]._discretize(n_samples[t],random_state,replace)\n",
    "        if n_Markov_states is None and method != 'input': return\n",
    "        if method == 'input' and (Markov_states is None or\n",
    "            transition_matrix is None): return\n",
    "        if n_Markov_states is not None:\n",
    "            if isinstance(n_Markov_states, (numbers.Integral, torch.Tensor)):\n",
    "                if n_Markov_states < 1:\n",
    "                    raise ValueError(\"n_Markov_states should be bigger than zero!\")\n",
    "                n_Markov_states = (\n",
    "                    [1]\n",
    "                    +[n_Markov_states] * (self.T-1)\n",
    "                )\n",
    "            elif isinstance(n_Markov_states, (abc.Sequence, torch.Tensor)):\n",
    "                if len(n_Markov_states) != self.T:\n",
    "                    raise ValueError(\n",
    "                        \"n_Markov_states list should be of length {} rather than {}!\"\n",
    "                        .format(self.T,len(n_Markov_states))\n",
    "                    )\n",
    "                if n_Markov_states[0] != 1:\n",
    "                    raise ValueError(\n",
    "                        \"The first stage model should be deterministic!\"\n",
    "                    )\n",
    "            else:\n",
    "                raise ValueError(\"Invalid input of n_Markov_states!\")\n",
    "        from discretize import MarkovSampler\n",
    "        if method in ['RSA','SA','SAA']:\n",
    "            markovian = MarkovSampler(\n",
    "                f=self.Markovian_uncertainty,\n",
    "                n_Markov_states=n_Markov_states,\n",
    "                n_sample_paths=n_sample_paths,\n",
    "                int_flag=int_flag,\n",
    "            )\n",
    "        if method in ['RSA','SA','SAA']:\n",
    "            self.Markov_states,self.transition_matrix = getattr(markovian, method)()\n",
    "        elif method == 'input':\n",
    "            dim_Markov_states, n_Markov_states = (\n",
    "                check_Markov_states_and_transition_matrix(\n",
    "                    Markov_states=Markov_states,\n",
    "                    transition_matrix=transition_matrix,\n",
    "                    T=self.T,\n",
    "                )\n",
    "            )\n",
    "            if dim_Markov_states != self.dim_Markov_states:\n",
    "                raise ValueError(\"The dimension of the given sample path \"\n",
    "                    +\"generator is not the same as the given Markov chain \"\n",
    "                    +\"approximation!\")\n",
    "            self.Markov_states = Markov_states\n",
    "            self.transition_matrix = [torch.tensor(item) for item in transition_matrix]\n",
    "        self._flag_discrete = 1\n",
    "        self.n_Markov_states = n_Markov_states\n",
    "        if method in ['RSA','SA','SAA']:\n",
    "            return markovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AssetMgt = MSLP(size=size, T=T, sense=-1, bound=200)\n",
    "AssetMgt.add_Markovian_uncertainty(generator_augmented)\n",
    "\n",
    "for t in range(T):\n",
    "    m = AssetMgt[t]\n",
    "    now, past = m.addStateVars(N+1, lb=0, obj=0, name='asset')\n",
    "    if t == 0:\n",
    "        buy = m.addVars(N, name='buy')\n",
    "        sell = m.addVars(N, name='sell')\n",
    "        m.addConstrs(now[j] == buy[j] - sell[j] for j in range(N))\n",
    "        m.addConstr(\n",
    "            now[N] == 100\n",
    "            - (1+fee) * gurobipy.quicksum(buy[j] for j in range(N))\n",
    "            + (1-fee) * gurobipy.quicksum(sell[j] for j in range(N))\n",
    "        )\n",
    "    elif t != T-1:\n",
    "        sell = m.addVars(N, name='sell')\n",
    "        buy = m.addVars(N, name='buy')\n",
    "        capm = m.addVars(N, lb = -gurobipy.GRB.INFINITY, name='capm')\n",
    "        idio = m.addVars(N, name='idio')\n",
    "        m.addConstr(\n",
    "            now[N] == (\n",
    "                (1+rf) * past[N]\n",
    "                - (1+fee) * gurobipy.quicksum(buy[j] for j in range(N))\n",
    "                + (1-fee) * gurobipy.quicksum(sell[j] for j in range(N))\n",
    "            )\n",
    "        )\n",
    "        m.addConstrs(\n",
    "            now[j] == capm[j] + idio[j] + buy[j] - sell[j]\n",
    "            for j in range(N)\n",
    "        )\n",
    "        for j in range(N):\n",
    "            m.addConstr(past[j] == capm[j], uncertainty_dependent={past[j]:j})\n",
    "            m.addConstr(past[j] == idio[j], uncertainty={past[j]:f(alpha[j],sigma[j])})\n",
    "    else:\n",
    "        v = m.addVar(obj=1, lb=-gurobipy.GRB.INFINITY, name='wealth')\n",
    "        capm = m.addVars(N, lb = -gurobipy.GRB.INFINITY, name='capm')\n",
    "        idio = m.addVars(N, name='idio')\n",
    "        m.addConstr(v == gurobipy.quicksum(now[j] for j in range(N+1)))\n",
    "        m.addConstrs(\n",
    "            now[j] == capm[j] + idio[j]\n",
    "            for j in range(N)\n",
    "        )\n",
    "        for j in range(N):\n",
    "            m.addConstr(past[j] == capm[j], uncertainty_dependent={past[j]:j})\n",
    "            m.addConstr(past[j] == idio[j], uncertainty={past[j]:f(alpha[j],sigma[j])})\n",
    "        m.addConstr(now[N] == (1+rf) * past[N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AssetMgt.discretize(n_samples=100,method='input',Markov_states=Markov_states,transition_matrix=transition_matrix,random_state=888,)\n",
    "# AssetMgt.set_AVaR(l=0.5, a=0.25)\n",
    "# AssetMgt_SDDP = SDDP(AssetMgt)\n",
    "# AssetMgt_SDDP.solve(max_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/lingquant/msppy/blob/master/doc/source/examples/portfolio_optimization/portfolio.ipynb\n",
    "\n",
    "# https://github.com/lingquant/msppy/blob/master/msppy/utils/statistics.py#L104\n",
    "# https://github.com/lingquant/msppy/blob/master/msppy/sp.py#L163\n",
    "# https://github.com/lingquant/msppy/blob/master/msppy/msp.py#L111\n",
    "\n",
    "# https://optimization-online.org/wp-content/uploads/2019/05/7199.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
